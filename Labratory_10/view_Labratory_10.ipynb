{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE_1cwdkw87d",
    "outputId": "bb97d97d-d8a1-4d4b-fd92-5dd7a5df0c65"
   },
   "outputs": [],
   "source": [
    "!pip install lightning evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "skRYnA_zkIwg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_paps_dtVSk"
   },
   "source": [
    "### **BART-Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L9IP8tzHkV_-"
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "  def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(d_model,d_ff)\n",
    "    self.lin2 = nn.Linear(d_ff,d_model)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  def forward(self,x):\n",
    "    return self.lin2(self.dropout(F.gelu(self.lin1(x))))\n",
    "\n",
    "class SelfAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,attn_mask=None,key_padding_mask=None):\n",
    "    h,_ = self.attn(x,x,x,attn_mask=attn_mask,key_padding_mask=key_padding_mask,need_weights=False)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class CrossAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,attn_mask=None,key_padding_mask=None,mem_padding_mask=None):\n",
    "    h,_ = self.attn(x,mem,mem,attn_mask=attn_mask,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,key_padding_mask=None):\n",
    "    x = self.self_attn(x,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.cross_attn = CrossAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,tgt_key_padding_mask=None,mem_key_padding_mask=None,causal_mask=None):\n",
    "    x = self.self_attn(x,attn_mask=causal_mask,key_padding_mask=tgt_key_padding_mask)\n",
    "    x = self.cross_attn(x,mem,mem_padding_mask=mem_key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uSoM-C6oqJXL"
   },
   "outputs": [],
   "source": [
    "class MiniBART(nn.Module):\n",
    "  def __init__(self,vocab_size,d_model=64,n_heads=2,d_ff=512,num_enc=2,num_dec=2,max_len=128):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(vocab_size,d_model)\n",
    "    self.pos_emb = nn.Embedding(max_len,d_model)\n",
    "    self.enc_layers = nn.ModuleList([EncoderLayer(d_model,n_heads,d_ff) for _ in range(num_enc)])\n",
    "    self.dec_layers = nn.ModuleList([DecoderLayer(d_model,n_heads,d_ff) for _ in range(num_dec)])\n",
    "    self.lm_head = nn.Linear(d_model,vocab_size,bias=False)\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "\n",
    "    def add_pos(x):\n",
    "      b,L = x.shape\n",
    "      pos = torch.arange(L,device=x.device).unsqueeze(0).expand(b,L)\n",
    "      return self.tok_emb(x) + self.pos_emb(pos)\n",
    "\n",
    "    src = add_pos(src_ids)\n",
    "    tgt = add_pos(tgt_ids)\n",
    "\n",
    "    # encoder\n",
    "    mem = src\n",
    "    for layer in self.enc_layers:\n",
    "      mem = layer(mem)\n",
    "\n",
    "    # causal mask for decoder self-attn\n",
    "    L = tgt.size(1)\n",
    "    causal = torch.triu(torch.ones(L,L,device=tgt.device)*float(\"-inf\"),diagonal=1)\n",
    "\n",
    "    out = tgt\n",
    "    for layer in self.dec_layers:\n",
    "      out = layer(out,mem,causal_mask=causal)\n",
    "\n",
    "    logits = self.lm_head(out)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4ymyIrXxHDQ"
   },
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557,
     "referenced_widgets": [
      "3e2a987b97664795bda124cdb3bbdd13",
      "3ad99117bff54d3da620c176d63bb424",
      "037ba22142fc49f2b0dca8e694b76acf",
      "145e8ac31c2548089c94e60744a97919",
      "c645138c20d943aa9103782fab33bd11",
      "22fdb6b8aa5e40e895e5f517a728fcbb",
      "f0360708bad4432b9d9a2ffd64ae336c",
      "ed27bc6c229e450bb0f3738b868dd9dc",
      "19dc6b466b414eb9868cca7b25eeb434",
      "0d4e6d016d614cb19560f1545171f2d5",
      "6c48995e8d0a409c829252569329f42f",
      "521ebd0b4b804dcb96418f22f67ed579",
      "6089f6cb8790436890e2865280ca7125",
      "ce6505203940407f813a7674f9aa7faa",
      "8163ea9ef0c14dc390971ebb55214049",
      "263b05ffb527417e883e5d2f086b57b4",
      "eafac4c90103442cae5d42791bd8eca1",
      "c2272b07dd2a43999dd28a47c30a1b68",
      "ff75a247f74d4d53864881daf58eedaf",
      "8255d3fcd3584d04ba121c95a4012802",
      "2e811ef74ae14eab91b7d88d1326c160",
      "f4f82fdd6b6441a1ab366c6d0c46c7c7",
      "5b6c21a561284502964a32a437e1d3ee",
      "20a0cdf78b334daaacfdd2ea38725ef1",
      "255acca1ec2b42e8999af2c265c9c378",
      "55960519ce25495585050721f82e6b3d",
      "ffab7c3bd38248bd95d4c0f37923dba5",
      "6ef5e848185d4bd195c810996a3f4721",
      "518e906b87944ebead20c74a95148248",
      "e0fe7c8820ac4388a292c3c8b3a5126e",
      "b92b593b088741cf994849d84bc55bd4",
      "36aeaa625928427382f1dfe8e2b43216",
      "9893f1fc0fe345b588779430729dd807",
      "3613e98261ec4845ad4d87ec3f076c1b",
      "f24e81d0e804481caeec1888174c3d45",
      "5eedafac4db544009caeab4ee1017a0f",
      "6bb8dec0e7644ae2be9dde0f963bd514",
      "1e3aaf5e450b488ca46e95151b4a4d8f",
      "ca0718e01ce14784a51e59ce8e809506",
      "047ebbf3a9724505929a84dde8014070",
      "1e50d8f32c4f4459bd00ccbcbcd1283b",
      "1a6794588251419198a6bf13378d9b84",
      "3daeb3b9b97840bda0fb9b93e5b0a99d",
      "b354a42fec3440da9f1ee4a6f582d2ed",
      "acd3f12ad82b433eacbce34bec4423b2",
      "c857c5366cf940ecbd80cbbd7d3cc156",
      "9b7f00d8fb2f4d0084322f75e963e4d6",
      "0bc7ed9031f143d180958f36ad2dc01e",
      "a5710895ceb5472ab18f8cf2b4fceef1",
      "0169ee9658e644a990cc2ed0c9f7148c",
      "73dfde77eb184d5080631073251e1080",
      "bfb4579c6efa4bc19aa52a13f251b14b",
      "71ee5c8561574cea9114e528eb15704a",
      "ddc9065f7ca3493f89e56b41d9eb56f3",
      "4710c2ce74ce43fb9d9b324f001855b2",
      "608f70833b2c4089a5c2aa219686818f",
      "a3a973ab1fec48efadd3fcd4554598fb",
      "c592632c7e334fc59a5a005d77167fa8",
      "cda213e4e5924de4878289af7252d07a",
      "c84324c2fcc14244bffad9a5ea24f5e5",
      "85e1b1ba47a7497da96c4f9bcdcce2f5",
      "6c9ee26ecea54b2d8d20808bf0a6796e",
      "4821fd14df8447449e13d913e6755fb8",
      "2fb3e799124a41bfad918d2c365267c2",
      "291a98be87dc486d91d154319b3baf6d",
      "d124a533dc3d41c294431f346e2b381d",
      "d150342c01184f198d4e1df2b3f5acbf",
      "e2645246fab546afbeff0641597a276f",
      "048458f0a55f4de59243b21fabf308b1",
      "12dc365d09fc4f52a978718e0dceb8d7",
      "80a2dc649ca94270a8744170c912f621",
      "38803ad19cad4354ad761ebd3eb28c01",
      "a8ca34482e7842bba2dd2a413d73f57c",
      "200eec3692394930bb29180199ddce6b",
      "75ba8384ca084fb981ae7ebfe8d5ddbd",
      "d7d6c0334a7d4d6eb563fc9ae5d14184",
      "436f68c810434c41bd8b4a7d45346399",
      "6284123f97af4575a690bc75ae61a367",
      "89d1eea8a50049468e1d939c102bfbf6",
      "36fd92a3fb5d404cb1fdcb0e2b4154ae",
      "b0a4686e087f40d6b6519b484dba744e",
      "81550de4823e46789fdcc16b2b0133fe",
      "e5ec8696fe104229a67b84cae551fdcf",
      "40fd730c6c13419696d63453225fa29c",
      "cc69d9ab0f7a4206b6c6137f42f996c0",
      "d63b3cef01f445cea20847f70344523b",
      "f36a5f8ba0374e9a9960abeb0ebd7c57",
      "3f9e4e509d124085912eb6699dde79df",
      "c6871355780c4ffd8a75cc7dd6113442",
      "d7784170122d44f49e7d78a6e127a8bb",
      "c6f21a5e5689489d8a2b48002b9f51e7",
      "37a2fb6be5e647eb8379ecab1f74455b",
      "da043571ba744b519d0710a52226880f",
      "e8757cb0f1684b39ad095f5272d4382b",
      "515a074f30e7431dbf4013e923e6fa82",
      "851fd981bf9b48f8b01bf771185dd332",
      "21a7a491cf594226848cbed5003ae32c",
      "1bed40d3ba4e4ceda55febcae8e10007",
      "8d482d7bf20141c5a830be5b85248511",
      "a947057696c7427e8fd491c6e20df61c",
      "1af1d2e8722e464e8f33635b6ffcdce4",
      "aaf4a3726642413cb9b2064ea03e131d",
      "f43c792a22c04bc6b5edda81219f7c36",
      "87e30aa43afd4c879e6ab482ee0dde3a",
      "f0acae40f7d94961b7e8b369663b0d9b",
      "24dd2b6e4031464fa043a1a9807a90c2",
      "8af251de7905442e98085d63ec2cd941",
      "71d754a7d8f1422487a763a0a7431341",
      "ed630a9e1f7a4dd1b7264b0c104286e3",
      "8759408bcd1f46f692190c342272c7a3",
      "fae26965af0144d09ae8f1029ee10fdc",
      "0e02a78f0945457d8f2f53845681cbad",
      "9384a40b8a99491e82b163fa72a50b58",
      "21952fbd6765411d9243c1af50261857",
      "84b0a1bcb2d5449bbe104b8d0295e111",
      "e30b8f5e26c74e4bbcce94a50f62e201",
      "05493cf7e14844fe8d352b46ee9ff368",
      "a9b3541293074d709055711c81d9d600",
      "875f3455a8e74446bb1302e9afc772e3",
      "dc9ca40d640a431cb9a316c1b17adbd5",
      "b4fa80cfc30b4f03a7862621fbacd7d2",
      "93aee92e08054f5c993a1f692852f7d2",
      "7032aa6b4b4443689c12d697af00ada7",
      "bed363f640b743ada70081eec8834f16",
      "20bee4226edf4f0ca2f825ee0ad89260",
      "11245a683f5844b98b12503f6deba07c",
      "84618a6642904c7abef42c4ef14349a4",
      "f847903ad7934fb08a904490c0fe5b40",
      "69fb846f61024afbab8811e902e5ccbb",
      "6bfd94a5d5c647efbbe4a53ec554498b",
      "f5dfadcd78be48509aa5efcfa60f93c9",
      "758ba1e593754263be03c5b80f8a3f00",
      "f868ca382a1e45aa87b49ccf3c06c269",
      "d9723c03cace4c779ec2bc011111b6e3",
      "8395ba8b1a66480db6ee819528cfe199",
      "6065a86b32cc4882929e19769b42e6bb",
      "14798b921702438a8f30723ac8f00fee",
      "138a93cbe5f94a11981499efa520464e",
      "311cb5570baa4d0bab733b511cfca04b",
      "0577763dcfa1449c893f86db5446c2d0",
      "61808e8f3afc423e915be935b091a18a",
      "8f9709476a0a4421b4ab105c477f9d91",
      "a12e7d90534b4f14accda00714284eb9"
     ]
    },
    "collapsed": true,
    "id": "kMj06JHIxLzr",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a661db65-5ef3-4153-c485-76f118aa588a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2a987b97664795bda124cdb3bbdd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521ebd0b4b804dcb96418f22f67ed579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6c21a561284502964a32a437e1d3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3613e98261ec4845ad4d87ec3f076c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd3f12ad82b433eacbce34bec4423b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608f70833b2c4089a5c2aa219686818f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d150342c01184f198d4e1df2b3f5acbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6284123f97af4575a690bc75ae61a367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6871355780c4ffd8a75cc7dd6113442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a947057696c7427e8fd491c6e20df61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae26965af0144d09ae8f1029ee10fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aee92e08054f5c993a1f692852f7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f868ca382a1e45aa87b49ccf3c06c269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\",\"3.0.0\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U4dQ6alZxaY-"
   },
   "outputs": [],
   "source": [
    "MAX_INPUT = 128\n",
    "MAX_TARGET = 64\n",
    "\n",
    "def prepprocess(batch):\n",
    "  inputs = tokenizer(\n",
    "      batch[\"article\"],max_length=MAX_INPUT,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  targets = tokenizer(\n",
    "      batch[\"highlights\"],max_length=MAX_TARGET,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGKUiO3eEGHf"
   },
   "source": [
    "برای این مدل 3000 داده آموزشی خیلی کم است.برای نتیجه بهتر داده آموزشی را بهتر کنید"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "65cf3f5dc2654c7f87e0f439de5a1c09",
      "d3252de5ecc64d45af31f56386ad2d48",
      "d671f4fa240d4df396c3da5c563291f1",
      "dd1cf010b6e64c23bf37c1c567a17095",
      "af867d604fc7414e9e0ba6a0fc8b5b5f",
      "d6a91d0aa2ca461a901e2e86e926e35f",
      "956d55de9eeb45dea1c3cf08327a2fc3",
      "50d15c6011bd4debbe62c1778c367191",
      "f16da8a998754a6a87a74e24e16bf100",
      "3353965b7f434fd490f617dd4d6bc4b5",
      "28c4bcbbcef34142a43db773aa00f18b",
      "9dbd4c5f9ee44cf9a498924399c104fc",
      "fa982dd31c4743fcb070be38c46f7140",
      "c838c4acac2846789cacc7f2cdf9d0ca",
      "603dadcc53d54af1af98fc68f6e40ad2",
      "e27a990166bc468e8489e3519b829b68",
      "f5369e3f4b134cfb96cce3a6c2f07100",
      "226c39ff158c4704bad992bf4dd1c7be",
      "15a404d3a3d448569fe542f73b48502d",
      "79e706e194704a348b532f8d02bcddb0",
      "bead25f8d2a848deb941d97e2a92e2f8",
      "977a846796bf4ca695359a3077624e63"
     ]
    },
    "id": "lCWjtT-zyM9d",
    "outputId": "246329cb-cea9-48f2-c156-4b1b40b0adf0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cf3f5dc2654c7f87e0f439de5a1c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbd4c5f9ee44cf9a498924399c104fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].select(range(20000))\n",
    "val_dataset = dataset[\"validation\"].select(range(4000))\n",
    "\n",
    "tokenized_train_data = train_dataset.map(prepprocess,batched=True,remove_columns=train_dataset.column_names)\n",
    "tokenized_val_data = val_dataset.map(prepprocess,batched=True,remove_columns=val_dataset.column_names)\n",
    "\n",
    "train_data = tokenized_train_data.with_format(\"torch\")\n",
    "val_data = tokenized_val_data.with_format(\"torch\")\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=4,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEQmv80_td6g"
   },
   "source": [
    "### **Lightning Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y6wmTWs4tkme"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "class LitMiniBART(pl.LightningModule):\n",
    "  def __init__(self,vocab_size,d_model=256,n_heads=4,d_ff=1024,num_enc=3,num_dec=3):\n",
    "    super().__init__()\n",
    "    self.model = MiniBART(vocab_size,d_model,n_heads,d_ff,num_enc,num_dec)\n",
    "    self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    self.val_preds = []\n",
    "    self.val_labels = []\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "    return self.model(src_ids,tgt_ids)\n",
    "\n",
    "  def training_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"train_loss\",loss,prog_bar=True)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"val_loss\",loss,prog_bar=True)\n",
    "\n",
    "    generated_ids = torch.argmax(logits,dim=-1)\n",
    "    preds = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(batch[\"labels\"],skip_special_tokens=True)\n",
    "    self.val_preds.extend(preds)\n",
    "    self.val_labels.extend(labels)\n",
    "\n",
    "  def on_validation_epoch_end(self) :\n",
    "    if len(self.val_preds) > 0:\n",
    "      results = rouge.compute(predictions=self.val_preds,references=self.val_labels,use_stemmer=True)\n",
    "      self.log_dict({f\"val_{k}\":v for k,v in results.items()},prog_bar=True)\n",
    "      self.val_preds = []\n",
    "      self.val_labels = []\n",
    "\n",
    "  def configure_optimizers(self) :\n",
    "    return torch.optim.AdamW(self.parameters(),lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m70jcKPY4end"
   },
   "source": [
    "### **Train_1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLPdr-4O4j29",
    "outputId": "e7bebe39-df2d-417a-9c2e-d533ceb3f0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = CSVLogger(\"logs\",name=\"MiniBART\")\n",
    "\n",
    "model = LitMiniBART(vocab_size=tokenizer.vocab_size)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=1,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "f4a8542446764ea1a6c39fc2bbf53d90",
      "55b40b7760e34c7c928f755c027ca61f",
      "00f65c0e3a27490f83241660695548c0",
      "e106448b842d4b7cbaee9a8a33699b55",
      "ade6dcd1415a462db759b11998ac1417",
      "41741d8838c04ba4be9c964135a5d646",
      "8a5c4dec79504f26b6ee5190842749db",
      "a36d489c2ced485fa54d58000fc41534",
      "c700fc50e23b4a81a273f1ab4e559ee3",
      "eae8f315334649489ada40d853fc7023",
      "39a748fd61d742ada97ca2642f75475c",
      "b488b6a9259d4b22be06a4bc33728148",
      "d28a05bfeb64470989eed638a2062da9",
      "5165a39cf5bc4efb8b0f6cd35b5774ae",
      "6ce40e89f95a4ab8b5a4b923c3e96b25",
      "1e2f93befcd44f458054d63c941da413",
      "ceb13b78ca1b4ee5815f2a1b16296099",
      "70dd0c1a29264246aa7cb16d5c552457",
      "9952174fd8c54f5680302f2dc01be44b",
      "54e4dd07f3404cc78923aab74bcd0102",
      "09ee7e01d1f7469284c84b12d3e93e1e",
      "c73fccef03cd49ca84b4176f3de77ce2",
      "762d3f871aec4ee59dda7744f7734d25",
      "d27af22b565b4f6f8246a590e375a6fa",
      "2deda3c77a2145e0b17afa5a85352ad3",
      "a4aa47902b5a41b89cf6895d595637db",
      "dfe33ab706b143ff9da468988f248ad4",
      "f90fa4b7942a42a099b4ecde6bea0b57",
      "93c63c6d57294aaca77c4db167d63876",
      "14d631dcf4cf4013a533645bd67d7d7a",
      "5aff4c46c3414938ab4edc81c5562048",
      "0ccd07ae8478499abb2fe5135f390ab4",
      "438a85e2782844039902f0147f64b238"
     ]
    },
    "id": "Gh-EjLIo53q6",
    "outputId": "6b2b228e-406d-4f97-bb25-0d2f52bc4cf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a8542446764ea1a6c39fc2bbf53d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b488b6a9259d4b22be06a4bc33728148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762d3f871aec4ee59dda7744f7734d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ngRy9F9D5g8"
   },
   "source": [
    "### **Train_2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "b1b6ce68200d428784f45ec2989244f0",
      "df347d718bb14fa39e4d40b8286d346d",
      "7f00fe2f079a449780ff7369c68e0ddf",
      "eab0ffdcf17a447e8e4f98a50dc05bf7",
      "cba29a7dc5524b1fb6c38dca4e97943c",
      "dc52041ead724a09983d2c2ad0420c69",
      "211610ba94a044c9945b1281d21e52a8",
      "9e84faaf88d34ac0ad209a11982fa55d",
      "85ba78a000014168be42aa7368cd6348",
      "bf8d1c99bbdf49ed8cff8293799e7fe1",
      "f07a02d30d324a2d8cf38343f50f1bbc",
      "95003beb86584c9cb3ad9b5071acf220",
      "6e35ecf533504c038ac512651953abde",
      "419aad56833c41e5ba06b10682cad333",
      "8f2ed69be9af47a9b4d24fadc0c060f7",
      "d152bf5578354dcdb49e338a3d5e1a9f",
      "7f302941267b494181773b338f2d16b8",
      "e23439a50c5e43369826369be2769a7b",
      "f604220240614e0ebf9ace7b08e68648",
      "35c7e842a1cd45a1b45e4ee6d8ed3429",
      "c24d20d1c46340448b31a4caee34aaf9",
      "123c2b65a4c640928e79024f287abe80"
     ]
    },
    "id": "JLXpk2jZDlLg",
    "outputId": "a5ca474b-77ad-47cb-be64-51aa5901ef31"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b6ce68200d428784f45ec2989244f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95003beb86584c9cb3ad9b5071acf220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_2 = dataset[\"train\"].select(range(20000, 50000))\n",
    "val_dataset_2 = dataset[\"validation\"].select(range(4000, 9000))\n",
    "\n",
    "tokenized_train_data_2 = train_dataset_2.map(prepprocess,batched=True,remove_columns=train_dataset_2.column_names)\n",
    "tokenized_val_data_2 = val_dataset_2.map(prepprocess,batched=True,remove_columns=val_dataset_2.column_names)\n",
    "\n",
    "train_data_2 = tokenized_train_data_2.with_format(\"torch\")\n",
    "val_data_2 = tokenized_val_data_2.with_format(\"torch\")\n",
    "\n",
    "train_loader_2 = DataLoader(train_data_2,batch_size=4,shuffle=True)\n",
    "val_loader_2 = DataLoader(val_data_2,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyyZzyrWEv54",
    "outputId": "5e07168a-277c-4c5a-b174-c658bdde2e58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_2 = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=2,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590,
     "referenced_widgets": [
      "052bf2c5e7c743d883228928e4f34ba7",
      "64ade193fe884cebb92a7d34600e2848",
      "93e8c231618d4f1197ddfd21f9c7defe",
      "09a2e206b21b4eecabb61d1005c423ce",
      "f60756768414415cb8450ad8a72bfbfb",
      "69439b1ffe5b4e8ca7cfc4704c4a227b",
      "399ad64ccf2d46c292f5a9cc7c5dc614",
      "52a0f0716ed445ee897eea1ad304685a",
      "e4f0857e4e124395b52edb310a45531d",
      "594333beefa3409f88bc1701fc46dfee",
      "c54d5a436cac4e1bb9d24cd37f8175f6",
      "5ac882d373f84ce5b203f45d60f9794e",
      "f920e39fc43042278ebdb63d2a83b5f0",
      "6918b737e6b04d2f916fd7b526f472f9",
      "16fd4c51a56d459386eb219d4aa1ec2b",
      "b8a2939fd24145b7b5dc92fad8839af2",
      "c110b341fe9c4f40a037443d0bcefa4c",
      "dbac9820f3774bf3b6f6f9941c3fc4c1",
      "8d370048c82b4238a4dd91b743a154ea",
      "db1b7ed633f24affb0b9c574e797a73f",
      "3e043db925e644f2826b0c67e91f2a0c",
      "e8295580a5774103b066f1609e03565e",
      "e02443f8183741a0ac10ea57be0c6279",
      "39235732b099403d83c70e5f6e1346bf",
      "1ec54e06338f4a449563cd0aa69f7bdd",
      "52164b88e1be48d3884839f541a55ae3",
      "0f96f8e2e0444210bc2f7920d57180f4",
      "a3343e5177ea4e86b100be08255d8fb3",
      "f9b178e36c604d2a8df2093412c4ef6d",
      "d79b97fc11cb4f50a17d49fb4e2b22d1",
      "5e5b4a8f12954805a021a982b1094318",
      "7cacd586e0a049b79266458ab236bd0c",
      "bfdd891d610f4a779623cfd5b60d097d",
      "15cc1ae505fb401f95426cc29b707e1a",
      "d944a5d9efcb4c2296d119ba82c250a3",
      "c42dc53df1fa49ea949fccc2b71e384b",
      "7645c43f2dde4693b90917e5619ee5e8",
      "3eea08113c804bd39ed13d4384018c1f",
      "d6df0d816d9c4d69a5f8b74948223c72",
      "284a98d0f8e84bec8cc38e6262910689",
      "c340bb0f64ba480a912ef26f8a0034e7",
      "4fef8324a4214b67a58d237cbe58d0a9",
      "0e19562c26a84e57acc5f53b465aaf28",
      "972b599f5f5d4dcfa3df7012f350eb68"
     ]
    },
    "id": "YTrQy72xECAX",
    "outputId": "afede17d-d792-466f-ec67-8a82d21adaef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:701: Checkpoint directory logs/MiniBART/version_1/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052bf2c5e7c743d883228928e4f34ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac882d373f84ce5b203f45d60f9794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02443f8183741a0ac10ea57be0c6279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cc1ae505fb401f95426cc29b707e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer_2.fit(model,train_loader_2,val_loader_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpqjtCXwHZgK"
   },
   "source": [
    "### **Train_3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9242c85c2075426691ea54892ed825eb",
      "ed7a1c63b2824a36ab641632890af42b",
      "08b020c05e2a4975a00dca727de779f2",
      "117c93fc1c3f4958abad2758770aaec9",
      "aae0d3253a4d4e74a1c97e8f42b11137",
      "9e2762251eaa45419854da4209a71cc8",
      "fa468dbcd01949cfb7f2fe3dcb1dc95a",
      "8bc6ea54f07c4eb79945186656606d48",
      "b9bd5e2593f94f2c8c02e369b35a5ead",
      "02ed6177ca1d44ce887752ff01f00443",
      "2cd5696c916c408dbf9de2a2a9fc11df",
      "d2d7ae13c03e4dccbd6c82d6f015bdba",
      "e69686b2b0df40f4ad222a1aaea1ac99",
      "b9808f7021974146b1b2a404a9f5d4f1",
      "523e0a5f698c46e283799ecaffbb1c77",
      "eb1833303c8d4520810e90fc9fa4da9b",
      "c835a16f27294e39b3bc3f39a8e47f18",
      "cf8b6b28dc594084a5553ba362f78f66",
      "5f5ca73cfcab4de08ddb28499fa1ffad",
      "843c3df5b9724f9abb8aea5181378fbc",
      "bc807df96db0490a94c954f1d4ae5541",
      "c659bb32714041da889ba724946f963a"
     ]
    },
    "id": "58x051fmHZgK",
    "outputId": "60382140-6f79-4393-df43-702556c5b3e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9242c85c2075426691ea54892ed825eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d7ae13c03e4dccbd6c82d6f015bdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_3 = dataset[\"train\"].select(range(50000, 70000))\n",
    "val_dataset_3 = dataset[\"validation\"].select(range(9000, 13000))\n",
    "\n",
    "tokenized_train_data_3 = train_dataset_3.map(prepprocess,batched=True,remove_columns=train_dataset_2.column_names)\n",
    "tokenized_val_data_3 = val_dataset_3.map(prepprocess,batched=True,remove_columns=val_dataset_2.column_names)\n",
    "\n",
    "train_data_3 = tokenized_train_data_3.with_format(\"torch\")\n",
    "val_data_3 = tokenized_val_data_3.with_format(\"torch\")\n",
    "\n",
    "train_loader_3 = DataLoader(train_data_3,batch_size=4,shuffle=True)\n",
    "val_loader_3 = DataLoader(val_data_3,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTmt1F0yHZgL",
    "outputId": "1d89e3b2-b4c1-4ae2-ec0a-cca87a9f26c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_3 = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=5,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590,
     "referenced_widgets": [
      "2882243a60c9442ab6fa8eb42de8adff",
      "c257dea6194a4407bb4c914fe4f792a6",
      "eac119686bcd446f962d7ea8cbdca56a",
      "1f47a7d728f142cba89014df86a68018",
      "1f0725c8ca7a4367b07321a4e933e22a",
      "139ee2c333f842b88097e3ee19bc743c",
      "3c14e72a1e5f40699833152579bd431d",
      "bd78f35037e144edac099b196040dcbe",
      "b6513feedebb4a0da40767ea1a13db96",
      "4aa63f81823e4169ac26c6007d6f40ce",
      "9595d3dfbdfa45909a48d72182d7a866",
      "a93d534b84a8448eab845409933e6501",
      "65bd3757aa6e4bc29cd792b177c357b7",
      "c2461a06173a49408439419e4aeca15c",
      "e1c7abc31ddc463dbc7f7895c50ad277",
      "c44ef04615194574843d97c69ca37388",
      "ba37d4eb128b4b9cad79d670896243c6",
      "f2701ec3345645c4b93dadb069b28919",
      "cfb33ed0ccf34de087b059eaa9640603",
      "eb3282cf25264a5e9e9796cfb6c77cc8",
      "2bb3fbc2e91049119e544b8807e5b5c8",
      "b1ff70d2a53f4543a861531a1f958b3e",
      "fca8c392170d46fe856970174e96e3a4",
      "07c117f4ebe846fbb96970185705b4b8",
      "c1e61b1431ef4086bd643458a765854c",
      "6f7ae394afe44a55a07bae27580ef57d",
      "59cadffcab3b4b3b8da60d1c0ef19538",
      "26e85013686e4ce3a7d56affd29d6e6c",
      "bb528225ee964290906df8ebe2097116",
      "ce302b1f82dc4170bd0f8a01578bb6f4",
      "3d13ae6c72f44e5b88a5d4b1d0ff2867",
      "c2e272c0eab34081b21d8f93cf90df97",
      "75eab3f1766b411585da87c00d9f225f",
      "9cbb46e56bc8479ea33f588b91948462",
      "e32d1826e0074150bffb9503a1204d96",
      "a6b6426bfdcd4efb8847a6e72e97c1fc",
      "e2a5ef244f384f9790ae733e004d5eea",
      "47ae4fdd98eb4dcd85ff2960fb3d7fc5",
      "3125548bd2e84962bfbc4a37ce072dc6",
      "289c6bed34ec4a96813e9eb9e9c5f6a2",
      "8625fec930d246f39bd7987eedc6513c",
      "3f4c03f0b098414e924eb7d2eb76e8e2",
      "77082b77fe964ac98f706219443407a0",
      "8aec204804564b679df33c72cdf62cae",
      "d69687ea910949a8a46b0ec98df378f5",
      "423e2224f50144d79927e2a62abc5d56",
      "fd2537f5a8894a71b8f6ed105552b4a5",
      "f75af0e6500e47bc9e33cd6c3772f6c7",
      "83ff4b9816e1428791b627bab3c5b353",
      "190a8e9469ac4b1bae960a0d09b2e4e3",
      "a509a6e34c3b46d38e58644e0fa46f27",
      "d8a52cee36f84ad18a00c1d790ae51a0",
      "fc6b56b0bbc54e7ca12bd2d8b8fd4c94",
      "ce64475f04884178bfdaf1ffdb77bf81",
      "44ebefed18a4421f8e699fe00962307f",
      "5bea6c2505de4dcfb78f8bb6464986f2",
      "a9f20ad3246b48dc816ec854f3557faf",
      "80ba547748694b8c852389e92b5c1b75",
      "8e3ccc80f86b4922ad7adc21d53037df",
      "9ab03000bcfd40658cdd645a073b5637",
      "ea93d982df474e00a9aee0080306bafa",
      "71a8b9902e574f27afc70b9941805ae1",
      "ff5565f001974a879e299fa05de0d081",
      "57340cbc962846fab08a211e04a013b4",
      "88c4d678dccb499abc0f1e540567dbce",
      "dbf5b67cf7d84c3faad93c475bbf58a3",
      "044355074a7c47dc9dd8897ebce483c9",
      "66561f926c764c9ea1184c96493057cb",
      "9a98e02a4b1d4b7cba6c52700723e6be",
      "37b85a8799014f8d9846f54a9f506a13",
      "e8df4d0efd474bbb9a4fa84f1e3f902c",
      "bc0d1be874ec41c2a16fdcc98c00a967",
      "b581c99c33054e1e9fec17b906344c1e",
      "8da710f37eda4a619888b78c2b69f958",
      "22044a4715e44bc4b2a227dfa69264c1",
      "a8ea816cb3bd4717b47ae24067ecc1f8",
      "b3cb00e7800c4bd9b882e3c41084ee72"
     ]
    },
    "id": "zVdehM8SHZgL",
    "outputId": "137f2ca0-714e-4ee1-e4eb-733be94047df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:701: Checkpoint directory logs/MiniBART/version_1/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882243a60c9442ab6fa8eb42de8adff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d534b84a8448eab845409933e6501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca8c392170d46fe856970174e96e3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbb46e56bc8479ea33f588b91948462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69687ea910949a8a46b0ec98df378f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bea6c2505de4dcfb78f8bb6464986f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044355074a7c47dc9dd8897ebce483c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer_3.fit(model,train_loader_3,val_loader_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMcAZkVtN57M"
   },
   "source": [
    "### **Train_4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "8453f0cc38a04b43a1578f14329d89bb",
      "db10ed584c1341688e02d013dc43d7ec",
      "24e3b5ddcc754399bebd882d631b95d3",
      "b82030eacc2647e99ab17f77f9e272f9",
      "8b68fb51dc9d429aba3a5f5a799daf8b",
      "637aacab5a4f4c53a2334fa262ca49c4",
      "16d14618a6a642ed89edec8dc0f2c91f",
      "7f563192ce25427c9f6b0f443c4e0913",
      "a508a75b5b7b447792051b03e401fa12",
      "5726323067d44413b3fa2f5a1201d857",
      "1b1b2cfa05b44a94a9762ee718230970",
      "42345888b46f4ff7b67da0c0a7f0ac78",
      "31cb73c8d06a40f1a6890d2b7d28412d",
      "c431d6ea4ec04b35af888b8b634554bc",
      "e48073c039d74d05b54ee2f0dcfe8bce",
      "acef0d94731043c189bfd0eb6194ae94",
      "b524a550051c4366953cc0a4ff884a43",
      "ba98905519d04a92837cc8617575389d",
      "f5d38ada63034828b48ae10f95be804a",
      "6b3537bb5e4d4142bdc0b73a4c480086",
      "4e940b279bc54054bf5e1c88c4a7d709",
      "82482a324c1a4834921b08a7febdcc25"
     ]
    },
    "id": "if_k0gRsN57N",
    "outputId": "26b0c27f-c83c-4ae8-f655-ab6b7e84cee1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8453f0cc38a04b43a1578f14329d89bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42345888b46f4ff7b67da0c0a7f0ac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_4 = dataset[\"train\"].select(range(70000, 100000))\n",
    "val_dataset_4 = dataset[\"validation\"].select(range(10000, 13000))\n",
    "\n",
    "tokenized_train_data_4 = train_dataset_4.map(prepprocess,batched=True,remove_columns=train_dataset_4.column_names)\n",
    "tokenized_val_data_4 = val_dataset_4.map(prepprocess,batched=True,remove_columns=val_dataset_4.column_names)\n",
    "\n",
    "train_data_4 = tokenized_train_data_4.with_format(\"torch\")\n",
    "val_data_4 = tokenized_val_data_4.with_format(\"torch\")\n",
    "\n",
    "train_loader_4 = DataLoader(train_data_4,batch_size=4,shuffle=True)\n",
    "val_loader_4 = DataLoader(val_data_4,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDDmxNOPN57N",
    "outputId": "6d4b9959-c397-43b9-c6a0-5a1587e8ac83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_4 = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=3,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622,
     "referenced_widgets": [
      "feff759297164c908a93153fe7bab84d",
      "5ed6debfe79e4bfb8f95e3ed239ef371",
      "072ceb07396a412396d8fe627f066fe6",
      "30a3fd4f6c384b17a4bcc3ee6a04926f",
      "867aef9d36274d32852561a6d82d1406",
      "e98ce95867054142b958ef333d0657c9",
      "6267a06be00145f196616d4a5896ac9f",
      "f37ca457d148449c8c93fb88a1656a33",
      "4276a3377885454886dff596488f049e",
      "4e05bf5e02b64f8ea07352fddb7bfe8f",
      "32331542e84d4ec99664bdef7df2c622",
      "22136c9aa6ae4be8bd1762d209183cb5",
      "07f0ededec50477bb3f0e604605b9644",
      "23b81b051bf64e0abef5df3055dd0c58",
      "ca1638795a6141ec8232df838805d7d9",
      "d664ffac56ea499c9ced1f04a141895f",
      "53dbac5970414654a566a15b79407e2b",
      "583840d8ec87483a9da4b9f017f93bcd",
      "65ddcfc41e384df4949a2a1cd7b75549",
      "663a5e0b71b6400ab941f4103c9a1c92",
      "f0af4343e1464421bbe207ef1b62be5c",
      "abac1b5e3efe453bb71c04ac9cca09e1",
      "cd7bfae7e50c46818013ea60604cc460",
      "5ab7a9f60e1b465fb93cc624264e4599",
      "8b4f47db64e44f20a258da72dab406cb",
      "b4d9414d69a24e248c54019030ae35d4",
      "f33513ef0d784810aafac59e07bdf98e",
      "087fc7808595432b8f4a1ba8e02593e4",
      "331435bc6ee34fcfa4ed45683bf35b22",
      "d0d71bda7ac6416cb6ff4838b7bd59ff",
      "8ea56d05f40043beb36f266c261b5b93",
      "63f8327a8e0a4f3cb1a3ee7e66cb254f",
      "d1de550c77c94d66a45c891477d65e15",
      "73eedc0103fc41ccb5de1d8e51b0cec3",
      "b021703940b8411dbb2ae7587293406d",
      "4fac390171634c42b253dd8906dd9696",
      "f43251e43b9b47d8abe0f59b2518765d",
      "9a7e8454898547e18a6a015c817dbc8e",
      "305141e31feb4e7daa01c21748646f6e",
      "4488ac4d62a04d27848a1b7fbe14ca6d",
      "3c1678b785954064910d3f29c1682c8d",
      "a2fcfdf288474caa9ed1f204d6a974b8",
      "92bc1deab6284283b370f4f4dfcc3fb1",
      "0aafe1fe19a24777867e1e838d19f35b",
      "1934dd25a3d34bd2a1eb7a3135fcd79a",
      "fc187c5026ee4de28bfbd87bd782419e",
      "5adc0341190343ad9c87b877324d64a5",
      "d95b9178731e4bde876845d00e6ca7df",
      "66a9ef3c925646d29c67ab0d946f6f0c",
      "653f09a355ed405bbc04b3c440c0fea1",
      "bfa4d5fff97e469684a124067061da30",
      "12fd35b6a457441390b7c5f89a8745cc",
      "48e76903f2c049ff8a8f0c46d4a87972",
      "78975bdeb59c473a909fcaa8f6abe5cc",
      "545a50cf080941b2b97fe40de4cfc45b"
     ]
    },
    "id": "YKnt7TRHN57N",
    "outputId": "26467595-c4eb-45c1-8bfc-d3b28d7f03fc"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:701: Checkpoint directory logs/MiniBART/version_1/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode\n",
      "----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | eval\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | eval\n",
      "----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "79        Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode\n",
      "----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.3 M | eval\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | eval\n",
      "----------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.192   Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "79        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feff759297164c908a93153fe7bab84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22136c9aa6ae4be8bd1762d209183cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7bfae7e50c46818013ea60604cc460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eedc0103fc41ccb5de1d8e51b0cec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1934dd25a3d34bd2a1eb7a3135fcd79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer_4.fit(model,train_loader_4,val_loader_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE1uy-x08Ooy"
   },
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tnUd7mAy8TbY"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model,src_text,max_len=64):\n",
    "  model.eval()\n",
    "  src_ids = tokenizer(src_text,return_tensors=\"pt\",truncation=True, padding=\"max_length\",max_length=MAX_INPUT)[\"input_ids\"].to(model.device)\n",
    "  tgt_ids = torch.tensor([[tokenizer.bos_token_id]]).to(model.device)\n",
    "\n",
    "\n",
    "  for _ in range(max_len):\n",
    "    logits = model(src_ids,tgt_ids)\n",
    "    next_token = logits[:,-1].argmax(-1).unsqueeze(0)\n",
    "    tgt_ids = torch.cat([tgt_ids, next_token],dim=1)\n",
    "    if next_token.item() == tokenizer.eos_token_id:\n",
    "      break\n",
    "  return tokenizer.decode(tgt_ids.squeeze(),skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qe9D-fqT_dgv",
    "outputId": "1382f10f-dc31-48be-e3fd-fbdaffdaa588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The U.S. is the first U.S. to lead a new Ebola outbreak in the U.S.\n",
      "The U.S. is the first U.S. in the U.S. in the U.S.\n",
      "U.S. is the first U.S. in\n"
     ]
    }
   ],
   "source": [
    "print(greedy_decode(model, dataset[\"test\"][9][\"article\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37plpX7STKbc"
   },
   "source": [
    "نتیجه -> نامفهوم"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
