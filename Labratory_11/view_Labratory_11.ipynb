{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE_1cwdkw87d",
    "outputId": "27cf4034-ecae-47f8-d9e1-694d194b1e26"
   },
   "outputs": [],
   "source": [
    "!pip install lightning evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "skRYnA_zkIwg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import evaluate\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_paps_dtVSk"
   },
   "source": [
    "### **BART-Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L9IP8tzHkV_-"
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "  def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(d_model,d_ff)\n",
    "    self.lin2 = nn.Linear(d_ff,d_model)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  def forward(self,x):\n",
    "    return self.lin2(self.dropout(F.gelu(self.lin1(x))))\n",
    "\n",
    "class SelfAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,attn_mask=None,key_padding_mask=None):\n",
    "    h,_ = self.attn(x,x,x,attn_mask=attn_mask,key_padding_mask=key_padding_mask,need_weights=False)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class CrossAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,attn_mask=None,key_padding_mask=None,mem_padding_mask=None):\n",
    "    h,_ = self.attn(x,mem,mem,attn_mask=attn_mask,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,key_padding_mask=None):\n",
    "    x = self.self_attn(x,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.cross_attn = CrossAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,tgt_key_padding_mask=None,mem_key_padding_mask=None,causal_mask=None):\n",
    "    x = self.self_attn(x,attn_mask=causal_mask,key_padding_mask=tgt_key_padding_mask)\n",
    "    x = self.cross_attn(x,mem,mem_padding_mask=mem_key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uSoM-C6oqJXL"
   },
   "outputs": [],
   "source": [
    "class MiniBART(nn.Module):\n",
    "  def __init__(self,vocab_size,d_model=256,n_heads=4,d_ff=1024,num_enc=3,num_dec=3,max_len=512):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(vocab_size,d_model)\n",
    "    self.pos_emb = nn.Embedding(max_len,d_model)\n",
    "    self.enc_layers = nn.ModuleList([EncoderLayer(d_model,n_heads,d_ff) for _ in range(num_enc)])\n",
    "    self.dec_layers = nn.ModuleList([DecoderLayer(d_model,n_heads,d_ff) for _ in range(num_dec)])\n",
    "    self.lm_head = nn.Linear(d_model,vocab_size,bias=False)\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "\n",
    "    def add_pos(x):\n",
    "      b,L = x.shape\n",
    "      pos = torch.arange(L,device=x.device).unsqueeze(0).expand(b,L)\n",
    "      return self.tok_emb(x) + self.pos_emb(pos)\n",
    "\n",
    "    src = add_pos(src_ids)\n",
    "    tgt = add_pos(tgt_ids)\n",
    "\n",
    "    # encoder\n",
    "    mem = src\n",
    "    for layer in self.enc_layers:\n",
    "      mem = layer(mem)\n",
    "\n",
    "    # causal mask for decoder self-attn\n",
    "    L = tgt.size(1)\n",
    "    causal = torch.triu(torch.ones(L,L,device=tgt.device)*float(\"-inf\"),diagonal=1)\n",
    "\n",
    "    out = tgt\n",
    "    for layer in self.dec_layers:\n",
    "      out = layer(out,mem,causal_mask=causal)\n",
    "\n",
    "    logits = self.lm_head(out)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "3956a9197ba14851bc2f2ea0519ee64d",
      "40ef2721b9244cea9045e27e343b9842",
      "27aa89f3ab694a12b82cf730a744c03b",
      "22114a101b2d4ae4a028e13cefddd256",
      "c84cde6f1a2f41b39cfb1de7488dc817",
      "e562e3eb15664de49a068f8e4487f8db",
      "85a61e352f9d4ee88cef436e237de037",
      "5f7893cb247045918be535bb00edf65f",
      "e84390aa7f8f48c8883312ca2122bef7",
      "5675596a2b7f4749a4c6f7a5e110121f",
      "1450a20330224348b012a5873bc38846",
      "fa633d06a5d142cf8fd94693439ee939",
      "f8d3c0958d8a4689a7d0356ea849491c",
      "48f0338821b84145830fb7ff16856b9e",
      "f3df1bd2c7f843539083c863a60e3467",
      "73edf74cceae4eed90ab5f6997496ba7",
      "9c470fe3cdfe4d9cb7806b9b2ccc3271",
      "a70aa963f8c34c0c86d55bff4d1293f9",
      "4acdc9fcfa054795a627b3d72ff666e4",
      "a76c3ff8264448ae914c419bae7ec3a1",
      "4d6b800df4dc45838544f81476430c25",
      "698ebff8f1654e6e97c8452281460b9c",
      "362c8486a7d744beb77e27483b8a7331",
      "db1cd2ab607a40bebf7b949fd7b25d87",
      "1ba6f60a20594301932c2d8d518b1c27",
      "1c2355a9106e48b0b97053d8f8abbcd7",
      "d78e73cb2d4d4a92a13d6251532a807a",
      "8ead7a4719764cea8a5b30e3116b9fc0",
      "8a887bb42a46403890a30d18e244cac3",
      "f0effc660a8a453eac9ed89b2d735c4b",
      "04fcd33ec63549a7a320d465ad0e7289",
      "3e4c03009532449099bebb7ae3ecaffb",
      "4de3c292d99849f099896cb403e3b78f",
      "c66e8707eb684b609d9bcb42742d7a41",
      "79b564bf88bb46cb9a418268e485731c",
      "90f3483f50e941d2b130a7116bccb01e",
      "38adc1d2474f4e9e95ec3c1a6bb9982c",
      "beab34d557284daaa5e1f18c34264456",
      "c9b042e7ce6349c89d37557bafe0af31",
      "ad123b5e2d0f47699c5625d050e9ff9f",
      "7f0315b0798e41c1876615ad70415890",
      "32b8035ed10248588e0a41ac585f8d3b",
      "9bec5943b78b4e6fbd1522c5ef2a3d15",
      "903cacf6bd4a4bf0bfa0e1be23cc69be"
     ]
    },
    "collapsed": true,
    "id": "D0Yb7ydHHavQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e83c01a5-a3b8-4d9f-b99b-eaeaef2700f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3956a9197ba14851bc2f2ea0519ee64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa633d06a5d142cf8fd94693439ee939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362c8486a7d744beb77e27483b8a7331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66e8707eb684b609d9bcb42742d7a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "MASK_ID = tokenizer.mask_token_id\n",
    "PAD_ID = tokenizer.pad_token_id\n",
    "BOS_ID = tokenizer.bos_token_id\n",
    "EOS_ID = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWBD-P54GUpv"
   },
   "source": [
    "## **PRETRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc1Mfus3T3sG"
   },
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "cc5f25e1181045a0a2bb5f4c97a2f015",
      "d8a53866beb444798c557383edcd1a75",
      "db67c0f8cd6549778d3370ba058c1ed6",
      "b2244f7934cf452e880c90100e2b8651",
      "3f144d34c2f54a329173247b046d4517",
      "32eadfc91d854b7fa9678d7a7a133046",
      "694491cf57cd498f90a0900b32c02070",
      "d4616acb7c654f18bac9fcbc90939422",
      "70fdca8c9f8546daa50b2d24441c583a",
      "56732cb4bce44ad0afa16d536634e7f1",
      "60870d7b38af409bb24f79f46b78e4dc",
      "dc18150afdbe402aab1710d719c9c69c",
      "118eb731eeb9425dba57ee81887a4334",
      "bcec8ffe0dca42d9988a84282d3170d6",
      "72b2734b63574f89a9d68000e1e5189b",
      "2503f9172c1b4b748bbca31a35b8ed10",
      "a062e48510d342a5b3cf7c7511381533",
      "fa4e3c1bd9e44a0bbf39c4d7aa9a69a6",
      "5d269a55ed374938bc7779bce3078aca",
      "dc5b65aa742c44a293bdd6e665e1ad70",
      "e71bf2d9b6b14186baf3b26be448af96",
      "0b8d1d452dc04e10b5a88bf74d1423fe",
      "04f5c8e55ed2407bb3acdda066b847ff",
      "0cb36acff2ba409590ba7584643e65b7",
      "ee28814b0f4448a0bc60b5c82b55f198",
      "95e740db57894daf91d7f3c83264b2b7",
      "f9870524ffb7463eb41bb7598cef8ce1",
      "1c502fce0c2e44219fb1e8538b60435a",
      "06d9946080cb445a8025f95670a89983",
      "938a43d80d9f4ffc9052dd6099c8f2ce",
      "7cd0cdb33ec14220a1f6539cd7527cf3",
      "669aea97d8da453497e5fa3b458ee90c",
      "54edf41a3c4d498f9d7f8b27a4cd7e83",
      "74738d3080714adbbf1a55b85f2750fe",
      "25020f340a6e4ef2bc8370e8b5899bd0",
      "eba1215568d64c6ba6f0727f3eba2ddb",
      "a038fc9d589349adb95db4b523074f74",
      "fffc05b17c4444d081cc8d3c5f6cfa88",
      "96bebe3f547a4dd79f9a56748ac978f5",
      "ff62e043da844f43857ec328e6359829",
      "ccf32573edae4d2385e285fa714a6b1d",
      "73b608fc997448448531f6378bd6402f",
      "4c35318bcdb840aaaaa11146071bd3c1",
      "fdca6d8967634c48ba3507bbdbea16dc",
      "2635977a2481412a98616aea901070df",
      "707c8039629f46daad194f4f61f0cfd6",
      "e1fcb64341bd49d7bb0a888e0ef6b5a8",
      "018e8baafd8b44b7ac6d58eab00c15fe",
      "800f7f03435748d0b66c0011f0fedbf4",
      "a6993482d8d44179aa0c774629320951",
      "704fc72fdda0481fa5a322b046908899",
      "7f39b586ee8545c994c3aadc8884c220",
      "d5a2fe9e376941c0aae90f42da9fced5",
      "333bde7dfb184031a41e7ec78ab315e3",
      "d095e32088094f1bab89d8abb6ea2d96",
      "58d6b65434bc4667a5ddf932b48edcbe",
      "fc6d1b7a7cc149118f610dda753ccfc4",
      "3ec06af2ed804237a005a9ca98f1dc17",
      "bbc167d286b44f4aa886ea9c6d159f72",
      "f429b89fd1ce4384bfb69cd9a78c2ed5",
      "a316ce38e9f44636bce9224d7ebc3c7d",
      "4e27e73250144a15bad795ea4ffec42d",
      "9d9cdb70b1c241d2bd6d958c70c85856",
      "8d3c66d0f6e149859c9683282c34dd0b",
      "3e42fdfb6f2f4483a21a604a914e331c",
      "da2956a33a354b40958f1387f9e282ea",
      "4e27076bf4894fb1b70b4a1e0b766853",
      "1eb2fcfb429d47cab7d8c7e066bce766",
      "2fad9b2c1c03428d871f3017b43b7a4f",
      "88f16cd9ac494b39b2df3084623293dc",
      "63635425012e4670b0982c9c9e295ca3",
      "3f6c7a585a5249cbb1219aa2199b25be",
      "4fb549843ce34d9fa1d7e055ff7f335a",
      "fd72622240c44618a40f81f9a931cbd1",
      "d0ce025cd0034598943a877338be35f3",
      "f639b45bc81840aa9433d8230bc9a6b3",
      "6d3c421506ee4c27ae80518070793bd1",
      "d67f16b624db48ea9dd662ce0410ca27",
      "ab1af95b326c4fe39a7b9d22b51a9f32",
      "eb9f46e645234087af909bcf0570e840",
      "2cd73f8f81e24c459a0da82f39187822",
      "ad855dffebfa46dca10562b31e7fbe50",
      "130ee8ee68424cfba723d1760804cd24",
      "1ced684affcd4be480aa40baacd89dd4",
      "a28dc22cc0fe492aa48f771271c900cc",
      "2b1255140aa54da4a6efa9a32232dc91",
      "6f15ade1ff684e21be817f14c3474f18",
      "aabbd764905f43918b69463c4619081e"
     ]
    },
    "id": "GbsviNz8Gg7C",
    "outputId": "41918580-e0f4-452e-bca0-6709cf822580"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5f25e1181045a0a2bb5f4c97a2f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc18150afdbe402aab1710d719c9c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/722k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f5c8e55ed2407bb3acdda066b847ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74738d3080714adbbf1a55b85f2750fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2635977a2481412a98616aea901070df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/655k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d6b65434bc4667a5ddf932b48edcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e27076bf4894fb1b70b4a1e0b766853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67f16b624db48ea9dd662ce0410ca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_INPUT = 512\n",
    "MAX_TARGET = 128\n",
    "\n",
    "# Ø¯ÛŒØªØ§Ø³ØªØŒÙ…ØªÙ† Ø®Ø§Ù…\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "train_txt = dataset[\"train\"][\"text\"]\n",
    "val_txt = dataset[\"validation\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuweYomLw9zG"
   },
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KLhgab9dJtcG"
   },
   "outputs": [],
   "source": [
    "# Ø­Ø°Ù Ø®Ø·ÙˆØ· Ø®Ø§Ù„ÛŒ\n",
    "def clean_lines(lines):\n",
    "  out = []\n",
    "  for line in lines:\n",
    "    line = line.strip()\n",
    "    if len(line) > 0:\n",
    "      out.append(line)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V8-mB9yyJ59-"
   },
   "outputs": [],
   "source": [
    "train_txt = clean_lines(train_txt)\n",
    "val_txt = clean_lines(val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GJlwXYB8KBlQ"
   },
   "outputs": [],
   "source": [
    "# Ø§Ø¨Ø²Ø§Ø± Ø¬Ù…Ù„Ù‡ Ø¨Ù†Ø¯ÛŒ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡\n",
    "def split_sentences(x):\n",
    "  out = []\n",
    "  s = []\n",
    "  for tok in x.split():\n",
    "    s.append(tok)\n",
    "    if tok.endswith(('.','!','?','.\"',\"!'\",\"?'\")):\n",
    "      out.append(\" \".join(s))\n",
    "      s = []\n",
    "  if s:\n",
    "    out.append(\" \".join(s))\n",
    "  return out if out else [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0lt-JuJ5LAYl"
   },
   "outputs": [],
   "source": [
    "# Ù†Ù…ÙˆÙ†Ù‡ Ú¯ÛŒØ±ÛŒ Ø·ÙˆÙ„ Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ù¾ÙˆØ§Ø³ÙˆÙ†\n",
    "def simple_span_len(lam=3):\n",
    "  L=0\n",
    "  p = math.exp(-lam)\n",
    "  F = p\n",
    "  u = random.random()\n",
    "  while u > F:\n",
    "    L += 1\n",
    "    p *= lam/L\n",
    "    F += p\n",
    "  return max(L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nobYXry2LnX5"
   },
   "outputs": [],
   "source": [
    "def text_infilling_token_ids(ids,mask_ratio=0.3,lam=3):\n",
    "  L = len(ids)\n",
    "  num_to_mask = max(1,int(mask_ratio*L))\n",
    "  masked = ids[:]\n",
    "  covered = set()\n",
    "  while len(covered) < num_to_mask:\n",
    "    start = random.randrange(0,L)\n",
    "    if start in covered:\n",
    "      continue\n",
    "    span_len = simple_span_len(lam)\n",
    "    end = min(L,start+span_len)\n",
    "    for i in range(start,end):\n",
    "      if i not in covered:\n",
    "        masked[i] = MASK_ID\n",
    "        covered.add(i)\n",
    "  return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WUohZE6zMzhq"
   },
   "outputs": [],
   "source": [
    "def sentence_permute(text):\n",
    "  sents = split_sentences(text)\n",
    "  random.shuffle(sents)\n",
    "  return \" \".join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c2rcYKj_M7Bm"
   },
   "outputs": [],
   "source": [
    "def apply_noise(text,do_sentperm=True,mask_ratio = 0.3,lam=3):\n",
    "  if do_sentperm:\n",
    "    text = sentence_permute(text)\n",
    "\n",
    "  ids = tokenizer(text,truncation=True,max_length=MAX_INPUT,add_special_tokens=False)[\"input_ids\"]\n",
    "  if len(ids) == 0:\n",
    "    return None\n",
    "\n",
    "  noisy_ids = text_infilling_token_ids(ids,mask_ratio=mask_ratio,lam=lam)\n",
    "\n",
    "  def pack(arr,max_len):\n",
    "    arr = [BOS_ID] + arr[:max_len-2] + [EOS_ID]\n",
    "    attn = [1]*len(arr)\n",
    "    if len(arr) < max_len:\n",
    "      pad_len = max_len - len(arr)\n",
    "      arr += [PAD_ID]*pad_len\n",
    "      attn += [0]*pad_len\n",
    "    return arr, attn\n",
    "\n",
    "  noisy_imp, noisy_attn = pack(noisy_ids,MAX_INPUT)\n",
    "  clean_tgt, _  = pack(ids,MAX_TARGET)\n",
    "\n",
    "  return {\n",
    "      \"input_ids\":noisy_imp,\n",
    "      \"attention_mask\":noisy_attn,\n",
    "      \"labels\":clean_tgt\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vhwWoNUvQtYI"
   },
   "outputs": [],
   "source": [
    "def make_tensor_dataset(texts, n_limits=None):\n",
    "  rows = []\n",
    "  count = 0\n",
    "  for t in texts:\n",
    "    ex = apply_noise(t,do_sentperm=True,mask_ratio=0.3,lam=3)\n",
    "    if ex is not None:\n",
    "      rows.append(ex)\n",
    "      count += 1\n",
    "      if n_limits is not None and count >= n_limits:\n",
    "          break\n",
    "\n",
    "  input_ids = torch.tensor([r[\"input_ids\"] for r in rows], dtype=torch.long)\n",
    "  attention_mask = torch.tensor([r[\"attention_mask\"] for r in rows], dtype=torch.long)\n",
    "  labels = torch.tensor([r[\"labels\"] for r in rows], dtype=torch.long)\n",
    "  return {\"input_ids\":input_ids,\"attention_mask\":attention_mask, \"labels\":labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qjTPDRhDScPS"
   },
   "outputs": [],
   "source": [
    "train_ids = make_tensor_dataset(train_txt,n_limits=150000)\n",
    "val_ids = make_tensor_dataset(val_txt,n_limits=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1LD8uVKT8JT"
   },
   "source": [
    "#### lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vscF1P2uTeWx"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "class LitMiniBART(pl.LightningModule):\n",
    "  def __init__(self,vocab_size,d_model=256,n_heads=4,d_ff=1024,num_enc=3,num_dec=3):\n",
    "    super().__init__()\n",
    "    self.model = MiniBART(vocab_size,d_model,n_heads,d_ff,num_enc,num_dec)\n",
    "    self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    self.val_preds = []\n",
    "    self.val_labels = []\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "    return self.model(src_ids,tgt_ids)\n",
    "\n",
    "  def training_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"train_loss\",loss,prog_bar=True)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"val_loss\",loss,prog_bar=True)\n",
    "\n",
    "    generated_ids = torch.argmax(logits,dim=-1)\n",
    "    preds = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(batch[\"labels\"],skip_special_tokens=True)\n",
    "    self.val_preds.extend(preds)\n",
    "    self.val_labels.extend(labels)\n",
    "\n",
    "  def on_validation_epoch_end(self) :\n",
    "    if len(self.val_preds) > 0:\n",
    "      results = rouge.compute(predictions=self.val_preds,references=self.val_labels,use_stemmer=True)\n",
    "      self.log_dict({f\"val_{k}\":v for k,v in results.items()},prog_bar=True)\n",
    "      self.val_preds = []\n",
    "      self.val_labels = []\n",
    "\n",
    "  def configure_optimizers(self) :\n",
    "    opt = torch.optim.AdamW(self.parameters(),lr=5e-4,betas=(0.9,0.98),weight_decay=0.01)\n",
    "    sch = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.1, total_iters=500)\n",
    "    return {\"optimizer\":opt,\"lr_scheduler\":{\"scheduler\":sch,\"interval\":\"step\"}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_JMhEINVTCr"
   },
   "source": [
    "#### dataloader , train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1j1-ge0nVXz2"
   },
   "outputs": [],
   "source": [
    "def to_dataset_obj(d):\n",
    "  return TensorDataset(d[\"input_ids\"],d[\"attention_mask\"],d[\"labels\"])\n",
    "\n",
    "class WrappedSet(torch.utils.data.Dataset):\n",
    "  def __init__(self,d):\n",
    "    self.input_ids = d[\"input_ids\"]\n",
    "    self.attention_mask = d[\"attention_mask\"]\n",
    "    self.labels = d[\"labels\"]\n",
    "\n",
    "  def __len__(self): return self.input_ids.size(0)\n",
    "  def __getitem__(self,idx):\n",
    "    return {\n",
    "        \"input_ids\":self.input_ids[idx],\n",
    "        \"attention_mask\":self.attention_mask[idx],\n",
    "        \"labels\":self.labels[idx]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4aJyN2pWUOT",
    "outputId": "29cb041d-ca18-4d08-9b21-89636dd7448c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train_wrapped = WrappedSet(train_ids)\n",
    "val_wrapped = WrappedSet(val_ids)\n",
    "\n",
    "train_loader = DataLoader(train_wrapped,batch_size=4,shuffle=True,num_workers=2)\n",
    "val_loader = DataLoader(val_wrapped,batch_size=4,shuffle=False,num_workers=2)\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"minibart_denoise\")\n",
    "lit = LitMiniBART(vocab_size=tokenizer.vocab_size)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    max_epochs=2,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604,
     "referenced_widgets": [
      "b371815ef4d94cbf928c56935b77c5bd",
      "d47e4b9599354c689c177eca47649daf",
      "e15ebec75a1a461e9c557af1f59765dc",
      "cc17eba9fb47406f9df3039c40984ce2",
      "dceb3557e04e457fa16ce41c5b99bfd7",
      "c58856982f4d47af9da0811097a18780",
      "7634fa2204fe4d0b905f32196cc554d3",
      "554c13b150954616b9d993b3e98daea7",
      "a5e570dd80664536bd86227eeba4e262",
      "4ec84379aa5147d1bca1a4ca2c90f4b6",
      "9e516d48fa924f2fa489a6841c2ecb6f",
      "97b51cae395446909410f6c2799e1fbf",
      "5fa4bebd79e94af9bfe8b75347347cfc",
      "88df0b2e96e44a7d86c27ff20699ff98",
      "ab16411c197f4bfd9bc776516f3387b0",
      "a2166b98169a4e44afe32466a5307cb6",
      "0a369d97beb24b2f8fb1dfdab9dcc455",
      "f78447a08f124d89bb1a1e27a18292b3",
      "dbc67385fa134dd7ae3f575379b664de",
      "67a08afd77b745e09493cbec14216e3d",
      "340751bbdeb14ccbb3e078ccbd1f8ba0",
      "eba1e966e0be49e6bffb6f8d974f50f8",
      "f7783b3e1934468e9601d5ea69d449e1",
      "904e63069eab4de683156489684105a9",
      "02e625e7be9b4e39bb584dfcd0d5d2de",
      "0ddf20ada3bd4b5d8f04fcb530d7a43f",
      "c158865135ab4f61ba9f05a2dcfcc0a6",
      "52bde00a20034d869fd3407ad7e1e254",
      "e6fd155f635947408d6679658d96d644",
      "31604874fe87406c8ca1fed593f684f0",
      "7397fd7d843b428796c1e004c677d4bf",
      "0441878607794ea8903b2c43e57c236b",
      "f0329fb41f44438c824ef319a4dc661a",
      "16030758eb5041a9967e5bf78fed33eb",
      "4a8caf8af1c544f7935555f0a6670786",
      "1508e67211194bee9830380b0ce69b52",
      "85c54970001f4f2a9c7269a6dfa05e9d",
      "df1fa6a002254c89a0a9860c8ec90b7c",
      "f42f33408e294ea18f0bd3736ea5d0fc",
      "401bc6ad3af040acaa640ae3718218c6",
      "2597e46bdabc461685254e65bcbefef1",
      "773d9a545fe046faaccd53ba1d743ae8",
      "e8bd79fd99ab41b59e1e5d5145941688",
      "9bad07baba704b798b8aa0bb434544f2"
     ]
    },
    "id": "GLyM61fXXHHy",
    "outputId": "0e0df65f-08fb-4b61-922c-de2b78ec18c9"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b371815ef4d94cbf928c56935b77c5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b51cae395446909410f6c2799e1fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7783b3e1934468e9601d5ea69d449e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16030758eb5041a9967e5bf78fed33eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn2Jzy9QGKhA"
   },
   "source": [
    "## **TRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4ymyIrXxHDQ"
   },
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305,
     "referenced_widgets": [
      "eaa8bfa4825c4aeeb458d89075819cdb",
      "cbb16c859e234ea7bcc35925a75c479a",
      "afe58002aff14ea3bc7001c026782c40",
      "d906b933a45d4983a9f09c04fb3050b8",
      "f627bb58d9df41208d9cc3fce35b4943",
      "36cc60f39031492fbbb5e25bd12148a9",
      "a0110f00993e4f43ac9538374d989d2d",
      "d617bdd8231947c2932640a362a12d11",
      "7698c6b983054a068bd9230b02bb0942",
      "65ebaf1c9e634b40add30ca7dac64f64",
      "5e1ed27f50ce4e0080923b608f8c4ee8",
      "35b37014917a4bbea16de5637d2c1a0f",
      "cb5d9b62a2e74569be4a22a51fefe919",
      "7127f54ed8454c64b15016a3fd51ac03",
      "069c2984edd342659a8fa84918a8b21e",
      "5607cf4f25b1473ebd74e8117fed853a",
      "f9291491415746539b0510af71e948bc",
      "f227369240724bb5a2cb524b3d0c8041",
      "a9455ce8726e4e9d8430f5de89020956",
      "f2be9af6207641b38eb048359f68b94f",
      "7a30e0622e04446aaca32d700c9a187e",
      "b842449d4dc14b829cc142bbf26e5a48",
      "25e555aa4a6c4f548bd306ba7665d6fe",
      "aa57d1159aba44159c003d73b2898944",
      "f60b24c110df448ea73b1c4fcc185d64",
      "727f84d1bf3e4ecbba7a7d10e07e084c",
      "6c1a15baa067439687992b43db2c5c41",
      "472a80ed13a64ed5a78994b1221fc931",
      "7fd8b4134a674010bb6fc3caf038455f",
      "1f833321fdd34a2ca5210a44fac6b90b",
      "43b4045b4b264211b34efef66188db61",
      "2e13c8fc2cc04060acf862fea2fc32a5",
      "598ce61c66504215ae0686b727b58e11",
      "decaa857063d4680bca4b122dacba346",
      "d9c5236815ae4c4f998a361394df4103",
      "007cd7d9a809461ea03479dc29007990",
      "f4df004b4a1d459f8c5685a0506e9696",
      "ea8aa1c4714d46c8b03e986ac13b261f",
      "6db4261e0f674076a289fe12e98485f2",
      "3edbb55f230b4fdebec1905697596d32",
      "3d7320a4b11f4296882de90235daa956",
      "ac838d451c5345859112d7205889da7d",
      "81eac79084d74ea0ab02298a527b6170",
      "cc2b092d2fc34e5eb1297de486d6dcbe",
      "1f1ad38884524dae979de6a3d4f46eb5",
      "1842a0aa5e1e4826b7783dcc9075e28b",
      "ffa9e721d27b4766bdf72a6de7928164",
      "e321fc52943747c29b6cebad06a2ec6c",
      "0abb9b3ec3e54804adf1fe113d35cec8",
      "4247a7ee4e80405dbf1eec645738a3a0",
      "9070ae7aaae64bdb8c4eb74afe8501c7",
      "650ac6b744f84d68993a6ee037b3b6c4",
      "732f067fab874856b68d49ec71587b71",
      "d891195421354bf195ce8df23d43760b",
      "7681707f197f40bb8aa7c76e1f90360a",
      "951768a87ef747f4bf2b94b3ebfa7661",
      "af6be190dc56445d87966ff94f2df187",
      "097882c9cf204184add0e9d6525eec25",
      "d0721d7ad22342d4b1d18b934e29dbe1",
      "66e16e4b6e54424181363ab4353a961c",
      "341f2267d006453d9a40e1a9af1ebad0",
      "4cd2a99acf184f8689c2cab7a0c1a5e7",
      "8543c645df4b42d8a2c3828b4771bb12",
      "666cd4d4ad314677bd723713018adddf",
      "20135698a08b41b7a70a988bcc1b6c73",
      "4ff0ed3ffd5548d98c345d1f939180f8",
      "ff00a26853e54671a1917792e97ffda5",
      "7670005f7dc04cfabd3b0dcffe5e69e3",
      "88e9bd72cb0847ad88de2a68c376f74d",
      "8c4b0621fabe4e53acb5e6617d3fad56",
      "fd3deb4db5ba48eca0a7106b800ed3cb",
      "5145399041ee46ee9d37ed6bd2a5f776",
      "978ebb1b8dd84e51af28c4f7af4aaac5",
      "5148bde376564fcabaf261be05641f5a",
      "a7fd1c8f103e4165b5b281e10fd57641",
      "12b5b89c4d8c445586448a0a5e03a12f",
      "818f6a227d2b4a7aa2dfc0a6d3e97821",
      "986bab499566418fb5ed1d042e63efe4",
      "1afb34a30fbb47529152fa6624d5f736",
      "88369bf420024c7999f988703078d9c7",
      "2f637a23855142a88e6e1cea41dd3722",
      "aeb80a3c3a984ea295a1aa48dc5579ae",
      "6dfaaaa9d2944a569c953a8831466f9a",
      "1b4138435c784644ae3200832c24b46a",
      "8deb52bf76ed41248b1179c1d807f1f9",
      "c0a633d133f1415eb2f5879409d2eeb9",
      "4dcd6279a97445e79771cafd23b54c80",
      "73a70e8790984df2ac9b18c629b2bfbb",
      "cde495e64ed641d1a0d7c58286148dc5",
      "f41d0554bfb44680b4279248ec58bb6a",
      "90882f755cc2449caafa45a4ec65f2b5",
      "5032d4f8e9db4fef9f3214ded488cd9e",
      "a2a3b70fa60047ea8d0015a154b97e8a",
      "ad3f89c3c0ee487da2d5d24bed2f313a",
      "680397115314498a83d7ade4fc97644d",
      "a96d8e0c396a4dd581e581c78ac8892a",
      "5a22576825794576b0a1c58d8d1c08bf",
      "0d31d051c1f540c6a6de3d1537b72d76",
      "349740948b8c4f2495a55e0f9c6d8eb6"
     ]
    },
    "collapsed": true,
    "id": "kMj06JHIxLzr",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c98a1478-3ec3-4287-e449-a9b507324f04"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa8bfa4825c4aeeb458d89075819cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b37014917a4bbea16de5637d2c1a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e555aa4a6c4f548bd306ba7665d6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decaa857063d4680bca4b122dacba346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1ad38884524dae979de6a3d4f46eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951768a87ef747f4bf2b94b3ebfa7661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff00a26853e54671a1917792e97ffda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986bab499566418fb5ed1d042e63efe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde495e64ed641d1a0d7c58286148dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_dmail = load_dataset(\"cnn_dailymail\",\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "U4dQ6alZxaY-"
   },
   "outputs": [],
   "source": [
    "MAX_INPUT = 512\n",
    "MAX_TARGET = 128\n",
    "\n",
    "def prepprocess(batch):\n",
    "  inputs = tokenizer(\n",
    "      batch[\"article\"],max_length=MAX_INPUT,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  targets = tokenizer(\n",
    "      batch[\"highlights\"],max_length=MAX_TARGET,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c79f80012025450d80e6f5b90acbb7c6",
      "458567a1a0194cd6991796eb7850d0c1",
      "55df7fd9e9d74756ac9958700db8309f",
      "c8716f182ae942f39d83f85b3e466a04",
      "d227110ea703452db44e209c4acbc537",
      "977150f376d145abb6e071a16a6fa813",
      "47a3019426e9453581b7759abfa5cd27",
      "943b3cab0f854c408c38fbde7ce18266",
      "e86da84d443b4afc8c299c68d09237f8",
      "1f0110a0a22d4b048204abe3db6aa478",
      "35c5ccda5587466f9c38f813baaf2c6c",
      "0d3087e76745454db3091495227e5d34",
      "317b2dee4a5e4b89b78cbdd211389215",
      "ff9eca0ed4534eadaf2e81e6cf1cb65b",
      "79fecc2d2f94424cbc61c0d42e873b25",
      "0f153f0d01df4ae9a72dae5f3fdb35f5",
      "5ca47cc29a5b422e8593d163f3a50bfe",
      "24e6f22b735b47cbb2998529965c4fac",
      "05dea20be6e94f7d885155aeac2eed1e",
      "d547f0746b4c49a4bcafeeaa5c152662",
      "5719abc1db8e4a3cb6f858f68b55d89f",
      "dceb4b6c39914386bd276b0ed863083e"
     ]
    },
    "id": "lCWjtT-zyM9d",
    "outputId": "50233a10-ea3a-45d4-b81c-bdf9681bb15a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79f80012025450d80e6f5b90acbb7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3087e76745454db3091495227e5d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cnn_dmail = cnn_dmail[\"train\"].select(range(80000)) #.select(range(80000))\n",
    "val_cnn_dmail = cnn_dmail[\"validation\"].select(range(6000)) #.select(range(6000))\n",
    "\n",
    "tokenized_train_cnn_dmail = train_cnn_dmail.map(prepprocess,batched=True,remove_columns=train_cnn_dmail.column_names)\n",
    "tokenized_val_cnn_dmail = val_cnn_dmail.map(prepprocess,batched=True,remove_columns=val_cnn_dmail.column_names)\n",
    "\n",
    "train_cnn_dmail = tokenized_train_cnn_dmail.with_format(\"torch\")\n",
    "val_cnn_dmail = tokenized_val_cnn_dmail.with_format(\"torch\")\n",
    "\n",
    "#train_loader = DataLoader(train_data,batch_size=4,shuffle=True)\n",
    "#val_loader = DataLoader(val_data,batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m70jcKPY4end"
   },
   "source": [
    "### **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tO04tRwDNwE",
    "outputId": "0c113a49-14f5-47ab-af97-95cd3b0f2190"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#train_cnn_dmail_ = train_cnn_dmail.select(range(80000))\n",
    "#val_cnn_dmail_ = val_cnn_dmail.select(range(6000))\n",
    "\n",
    "train_loader_cnn_dmail = DataLoader(train_cnn_dmail,batch_size=4,shuffle=True)\n",
    "val_loader_cnn_dmail = DataLoader(val_cnn_dmail,batch_size=4,shuffle=False)\n",
    "\n",
    "trainer_cnndmail = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    max_epochs=2,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654,
     "referenced_widgets": [
      "2aa91377d145433da2db5a8717308df9",
      "44ea624c1b6a4325946bad0ed69429bb",
      "f4a25c98fc594297b7132400aabfa921",
      "99f0efefacc245158c65168d03071d94",
      "10722aeec0a04e28869937b9357596cd",
      "7d21bddd41054bfa975f33c53fc68588",
      "e8ea51e502ec4066bef6b7c797846dc5",
      "93a4aa48ac5a43eea56ac89ae71e83b8",
      "d12608e1c1fd4673965c10c9267632b8",
      "680f0f7b0276425f8342f7b5c2eb6119",
      "d003ae79fbe9445fb775fa48ad28b6d7",
      "a60c42e4a7a74bb284d1a79b63f039a1",
      "6a328211e1994b46bcbb7c7712cdd647",
      "4d4f249bb1a74c7f9205ca12098662c9",
      "c9721d6dd8424955a0e853e88acf565d",
      "b70e785820a84a14b97fa2fd8fec06fb",
      "b14efb72f9e4414384505533faa88c70",
      "1feea6ddcd5447dab08947406b15e156",
      "84b3521204e94e1fb87df92f76e77263",
      "fd1b585d22f044258216ebd31aa3d305",
      "395fd362815f425bac151e7ffdde9cd2",
      "2f9c644665044dd09961495a12f6ef34",
      "26551f70ecb74d70a7bae04f8169f1db",
      "c119c1dfbff64c0984791fcc0b23cb65",
      "bb8cd28c9085496ca2c7736a948ce102",
      "2952f30d9bfe45a49c4101f3e4d4e22a",
      "4833f26f64944a61ac76e950f9b30779",
      "2c70cec58fd6436b9263d7d5691d9af3",
      "3f78fb41e0e547ada7ed50efb97175b4",
      "a213e950f7184d5697ed0d70bce35bec",
      "084cc9d7bb224dd59bc45ebe15c17381",
      "eddb4dac0d0d486584f36ef57d358b1c",
      "657a0af7031c4435a72043eca8676fbf",
      "4e79935ed2164cfe98a1adfe009b520b",
      "d0703b12362f42ce80d20cbe57bb86a1",
      "494a2820d58e400c97d2affeeada392d",
      "f6f1700c24b84b19b4a45ba0f4d400a7",
      "3e87ddd32bcf47ef9dbed92c63e53e58",
      "4f670ab9f7d645a59509285bb384c869",
      "a9b26a9db0b34129b7035eb9fe786909",
      "460690f2cb7e45618c0f09e8acc47bcd",
      "a300231341d948cb978433761560dae7",
      "d312952f42c949e5b04eafc76f2dcaec",
      "5f671c49fa164ac9b3451dc6310f3053"
     ]
    },
    "id": "Gh-EjLIo53q6",
    "outputId": "b2de80b6-9764-4acc-829e-7cd2e6b7cd93"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:701: Checkpoint directory logs/minibart_denoise/version_0/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa91377d145433da2db5a8717308df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60c42e4a7a74bb284d1a79b63f039a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26551f70ecb74d70a7bae04f8169f1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e79935ed2164cfe98a1adfe009b520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer_cnndmail.fit(lit,train_loader_cnn_dmail,val_loader_cnn_dmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjxsieTXvdT7",
    "outputId": "5317f94d-ec68-4773-e6cb-392f65d53422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/vocab.json',\n",
       " '/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/merges.txt',\n",
       " '/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/added_tokens.json',\n",
       " '/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Labratory_11_miniBAR_pretrain.pth\"\n",
    "torch.save(lit.model.state_dict(),save_path)\n",
    "tokenizer_path = \"/content/drive/MyDrive/Labratory_11_miniBAR_pretrain_tokenizer.json\"\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE1uy-x08Ooy"
   },
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "sCXz3lLQmwB6"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model,src_text,max_len=64):\n",
    "  model.eval()\n",
    "  src_ids = tokenizer(src_text,return_tensors=\"pt\",truncation=True, padding=\"max_length\",max_length=MAX_INPUT)[\"input_ids\"].to(model.device)\n",
    "  tgt_ids = torch.tensor([[tokenizer.bos_token_id]]).to(model.device)\n",
    "\n",
    "\n",
    "  for _ in range(max_len):\n",
    "    logits = model(src_ids,tgt_ids)\n",
    "    next_token = logits[:,-1].argmax(-1).unsqueeze(0)\n",
    "    tgt_ids = torch.cat([tgt_ids, next_token],dim=1)\n",
    "    if next_token.item() == tokenizer.eos_token_id:\n",
    "      break\n",
    "  return tokenizer.decode(tgt_ids.squeeze(),skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qe9D-fqT_dgv",
    "outputId": "b2b58524-753f-46d0-fd72-45a46f5f0002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW:NEW says, \"It's not toNEW:NEW's,NEW's't \"It's not toNEW:NEW'sNEW:NEW:NEW's not toNEW's not toNEW, says, says\n"
     ]
    }
   ],
   "source": [
    "print(greedy_decode(lit, cnn_dmail[\"test\"][9][\"article\"]))"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
