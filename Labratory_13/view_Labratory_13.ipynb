{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE_1cwdkw87d"
   },
   "outputs": [],
   "source": [
    "!pip install lightning evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skRYnA_zkIwg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import evaluate\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "96284848accf4ed9a78c856e64af1659",
      "4c26af7868464158a05aa700c5e41eca",
      "6c561707ef0f4251a97b50751b936e87",
      "93ac46ad12e94abc96a8bc021f7fca43",
      "c45c5bb44f0c4593a408f415223a79e6",
      "ac1892bdcf0d49eabe48cade1c0c7848",
      "9e01c730bcd34ed0a3848ccef94c2a47",
      "e00eb9a8088b4c2dafd3d033412284f8",
      "8f53b15c1f994b88be1e347b6e0b5b5d",
      "49ac4033c1004f56b2fe6b10db34e3a9",
      "adb45f835cd54914bc37b20a4eba8065",
      "480b02a6ee3043eea786b4667d24cc35",
      "0b78b1f953bb40859f569a6d62449d47",
      "24f8e7f69cab422fadac05d04c89b038",
      "1c4bc4234ac54329a86dfd57a8ec958a",
      "fa828ed5864944fd93f10d40ca736319",
      "eb451dcc54e84748a24a60b3640a84c4",
      "a96715773a134dfbaf16823cea79553a",
      "aeba0c50049f49fba271e1639322f0ab",
      "278024dd6b90444e94b4f92d5641097b",
      "fc9c0b4c025844d38186a3766f870c5d",
      "50bdcd8602a8487ab34060655a227d66",
      "c0619d1696f6414eb1c77503c144878d",
      "e7ff881abdc34d8485bdc906210cb83c",
      "744ad6ce06d4481e9a7b97aea610884a",
      "d63f3fc6e51b4f779f2fe370ca385a07",
      "9af3fc1dd15a487f85ede3ba4f609d69",
      "4ea5c95ce6274bc79b8e86979cd46547",
      "858c2b4056b14228945c88e6e6a0f37d",
      "a1bf9709a30a4022a7796618028e7e50",
      "99c6943f34b24d2a9107ee6f46da2d97",
      "b3279fec6e834635ba6ce54b98cbd667",
      "5c513d7fb5f44521957354dd1bb22727",
      "22132bb91dbf43da9763694ec326dcfb",
      "c190e3e286b94c3aa6bad90e583f0ed0",
      "a2035dff859046a4ba27880b62284249",
      "832fab3f4fe746c9acae00275989a368",
      "715ac422d5f9424091b8d2f941e6f35d",
      "4172ccd7a7644bb690f2015c5c71eeef",
      "0e1cc1a40c874943a6dcfe17e25112c1",
      "e4deb367dc0149d690c8e56956909670",
      "925c645f725645f6979234ff14335aec",
      "f8c672a5606f4dcbbcd31fbeb59ff6d1",
      "0ac06912b3fa4ff19892bacdc171ce88"
     ]
    },
    "id": "idFvXQRtb8Px",
    "outputId": "d178901a-6d1f-4b56-feb9-05a860f94995"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96284848accf4ed9a78c856e64af1659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480b02a6ee3043eea786b4667d24cc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0619d1696f6414eb1c77503c144878d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22132bb91dbf43da9763694ec326dcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "MASK_ID = tokenizer.mask_token_id\n",
    "PAD_ID = tokenizer.pad_token_id\n",
    "BOS_ID = tokenizer.bos_token_id\n",
    "EOS_ID = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_paps_dtVSk"
   },
   "source": [
    "### **BART-Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9IP8tzHkV_-"
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "  def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(d_model,d_ff)\n",
    "    self.lin2 = nn.Linear(d_ff,d_model)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  def forward(self,x):\n",
    "    return self.lin2(self.dropout(F.gelu(self.lin1(x))))\n",
    "\n",
    "class SelfAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,attn_mask=None,key_padding_mask=None):\n",
    "    h,_ = self.attn(x,x,x,attn_mask=attn_mask,key_padding_mask=key_padding_mask,need_weights=False)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class CrossAttn(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.attn = nn.MultiheadAttention(d_model,n_heads,dropout=dropout,batch_first=True)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,attn_mask=None,key_padding_mask=None,mem_padding_mask=None):\n",
    "    h,_ = self.attn(x,mem,mem,attn_mask=attn_mask,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+h)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,key_padding_mask=None):\n",
    "    x = self.self_attn(x,key_padding_mask=key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attn = SelfAttn(d_model,n_heads,dropout)\n",
    "    self.cross_attn = CrossAttn(d_model,n_heads,dropout)\n",
    "    self.ffn = FFN(d_model,d_ff,dropout)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "  def forward(self,x,mem,tgt_key_padding_mask=None,mem_key_padding_mask=None,causal_mask=None):\n",
    "    x = self.self_attn(x,attn_mask=causal_mask,key_padding_mask=tgt_key_padding_mask)\n",
    "    x = self.cross_attn(x,mem,mem_padding_mask=mem_key_padding_mask)\n",
    "    return self.ln(x+self.ffn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSoM-C6oqJXL"
   },
   "outputs": [],
   "source": [
    "class MiniBART(nn.Module):\n",
    "  def __init__(self,vocab_size,d_model=256,n_heads=4,d_ff=1024,num_enc=3,num_dec=3,max_len=512):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(vocab_size,d_model)\n",
    "    self.pos_emb = nn.Embedding(max_len,d_model)\n",
    "    self.enc_layers = nn.ModuleList([EncoderLayer(d_model,n_heads,d_ff) for _ in range(num_enc)])\n",
    "    self.dec_layers = nn.ModuleList([DecoderLayer(d_model,n_heads,d_ff) for _ in range(num_dec)])\n",
    "    self.lm_head = nn.Linear(d_model,vocab_size,bias=False)\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "\n",
    "    def add_pos(x):\n",
    "      b,L = x.shape\n",
    "      pos = torch.arange(L,device=x.device).unsqueeze(0).expand(b,L)\n",
    "      return self.tok_emb(x) + self.pos_emb(pos)\n",
    "\n",
    "    src = add_pos(src_ids)\n",
    "    tgt = add_pos(tgt_ids)\n",
    "\n",
    "    # encoder\n",
    "    mem = src\n",
    "    for layer in self.enc_layers:\n",
    "      mem = layer(mem)\n",
    "\n",
    "    # causal mask for decoder self-attn\n",
    "    L = tgt.size(1)\n",
    "    causal = torch.triu(torch.ones(L,L,device=tgt.device)*float(\"-inf\"),diagonal=1)\n",
    "\n",
    "    out = tgt\n",
    "    for layer in self.dec_layers:\n",
    "      out = layer(out,mem,causal_mask=causal)\n",
    "\n",
    "    logits = self.lm_head(out)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0H02R4daAK8",
    "outputId": "3bb9836a-f02c-4838-f53e-d2dfd0f09dff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBART(\n",
       "  (tok_emb): Embedding(50265, 256)\n",
       "  (pos_emb): Embedding(512, 256)\n",
       "  (enc_layers): ModuleList(\n",
       "    (0-2): 3 x EncoderLayer(\n",
       "      (self_attn): SelfAttn(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (lin1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (lin2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dec_layers): ModuleList(\n",
       "    (0-2): 3 x DecoderLayer(\n",
       "      (self_attn): SelfAttn(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (cross_attn): CrossAttn(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (lin1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (lin2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "d_model = 256\n",
    "n_heads = 4\n",
    "d_ff = 1024\n",
    "num_enc = 3\n",
    "num_dec = 3\n",
    "\n",
    "model = MiniBART(vocab_size, d_model, n_heads, d_ff, num_enc, num_dec)\n",
    "\n",
    "# Load the state dictionary\n",
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Labratory_11_miniBAR_pretrain.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWBD-P54GUpv"
   },
   "source": [
    "## **PRETRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc1Mfus3T3sG"
   },
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "ad63547e38a34983b0593e33b9dee4c3",
      "5c5020b1992944a0bb79a5a885e35474",
      "0eb60b4e31c8477cac8809633d6e56a5",
      "7c31205d07244ed297858337b66d289c",
      "63a6e5b386674f208d3e10e91a046fa7",
      "2f349dac80d54643aa77ba420b1cc790",
      "b5df2e2204ee4b25ad88e27c3d9dfbd6",
      "96ec9bb9a9994320a91bc5df1295ade0",
      "9e2375974c284323bb616e23ce9a954a",
      "83839779f2aa4b9c8746b4310193c1e5",
      "c80c4d3166c94b0fb2c3bd320e75b421",
      "e37208eeecd54fbbb8965d66092045d0",
      "56c52c16e4db43388d265a9dd42ae034",
      "b3c5d31bd1b2421ca4bcc494031bd3f6",
      "8f8c61e2f72a434582a14c11b0b14b71",
      "c4e0667bb9344bc3a209e20c2371242f",
      "561e24afc1be424eacb9458d56accbce",
      "c5e5f62d1b31455aa0b00676b5f2a752",
      "f8de6b11214543a2a5d6c88e83874cc7",
      "3f93b37f25c64c40a184d09465df0e89",
      "122c38985d9642708d452c1a96197c38",
      "494611ad7c2b4d5a9fa4a18ef377072b",
      "61a3ed152ceb4113af30fc1289d6e60e",
      "888e6065a8074e66b7bdfffc74e580fb",
      "7d20fa554a0543f3b9c3c5dd091c274e",
      "eaf11354d2eb48bda6bcb04579656109",
      "579073a280314a2091226f592d80b94f",
      "42cfc40b41d84f848dda9d2cf48652cb",
      "e056ddf73fec46b8a8b109eb99fd2dc6",
      "8585905e5e164014bf2ac7bdf592af46",
      "4ed0999554ab4c3495325e1e4c345ac3",
      "047012ff566d4753b2f9a78a9ed97407",
      "e3219407f1d9493792630c511d980353",
      "b854e64cad32436ca19ec42918fb564a",
      "b0ad180d45464ae4b04cf2ecd8c41d73",
      "601e6aaee2e14c6bbba0737cc248bae9",
      "e9c60bc3e11c4219a2c9ae7d254f65a7",
      "cc01065563c74b23baf43e5f53ff1a57",
      "35f7eff77cc245ab98a038eff516af1f",
      "252c38fd45784ae68b99cf999f3129a6",
      "7d4a4b3c4cf74d8fa7504b7b9afcf031",
      "75165f9b67da4adda96f0c937df4b4f9",
      "db00cc34f5144fc7a67ea7409a1e3d0f",
      "7d4995cbd3534662a3c6a3dd7e784ee2",
      "3298ed33656941acb963f47c61b55c04",
      "2a64f77f124d465cb74fd9c82fc7b8b8",
      "acbbb8910cb64b9d927089dc383be670",
      "261438d40bbd4b26b74baca171316704",
      "6db59c07d9584adba0446c91844cd172",
      "8409991ed5d04ce0a47eb495a144138e",
      "8c5127919ba1440980f6ee0b61631f7e",
      "2f791966526e49a1ade0ae94420da667",
      "371e03d8aa2a4f609bf08d5c0a00d108",
      "49905d7565314003ac2f78fa2a334e59",
      "cb3430ebde0340feaa045053634247a1",
      "4337cd22254b47efb7c442dd64a0d638",
      "8e94fa83053b41789757c2701d8e93bf",
      "44bd194866f44906b4628fd917631730",
      "737699815303453a8ce980425ef13b7f",
      "a797eec031d3421fb75c90a1f1f69661",
      "6a83f193c3df4e67890441c0fb04f448",
      "85b035797f4543a5b26d068781d9c384",
      "5def4078518949068fe6d78d3b6ffcfe",
      "4034ff2ef627483ea5c60ddb2721e27f",
      "ca0171aa00d44aae94c31d804701bb5a",
      "21bf563a66c245868a34fd642a24a0d1",
      "9054ea9474aa406ba33907357ccc73da",
      "9ad4a340e26d4d329d4695c66aa6f9db",
      "d68613d0a3da4653a62e746c7f990ac2",
      "8a331d47e9d140f2a99165bdddf5d81d",
      "544210bdd9d64d29adf931562cbe2387",
      "4a57101393284a78a97bd9a2be37f03d",
      "ba3b8c63489a4b8cbe4e27c12c7e5587",
      "a13adea18a9c421f930be40d9759b93d",
      "dadf92380dbd4a3ea59b452f59026d09",
      "e208a19dd6e546ab9647dd143d5c5416",
      "efad2a89919c4088a35c47faad21057e",
      "40129266d3b94d3fa5d21220852c57e5",
      "384e603e7cc44afd949cd06d98737dfb",
      "d44594d4639c4307b4ea72ecdcadf66b",
      "e4438d2d498a49fc845f892a552dfd23",
      "38f7da824dc1400eb58decc1a32700f8",
      "c9620f4f87084f888ef580eaf8b10c07",
      "a482c81e3c704d899ad75c554b3d2666",
      "d91d935c233f418ba126a893414084d9",
      "39629809327847c2ad114fdbea21ba8c",
      "9018d6cbf66445afbd310ed1051d4558",
      "dff13b1029fe4d78a2d03f1121ab4ebb"
     ]
    },
    "id": "GbsviNz8Gg7C",
    "outputId": "e4ee5c80-bba6-43ca-eb33-2b2af895cdac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad63547e38a34983b0593e33b9dee4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37208eeecd54fbbb8965d66092045d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/722k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a3ed152ceb4113af30fc1289d6e60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b854e64cad32436ca19ec42918fb564a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3298ed33656941acb963f47c61b55c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/655k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4337cd22254b47efb7c442dd64a0d638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9054ea9474aa406ba33907357ccc73da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40129266d3b94d3fa5d21220852c57e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_INPUT = 512\n",
    "MAX_TARGET = 128\n",
    "\n",
    "# دیتاست،متن خام\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "train_txt = dataset[\"train\"][\"text\"]\n",
    "val_txt = dataset[\"validation\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuweYomLw9zG"
   },
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLhgab9dJtcG"
   },
   "outputs": [],
   "source": [
    "# حذف خطوط خالی\n",
    "def clean_lines(lines):\n",
    "  out = []\n",
    "  for line in lines:\n",
    "    line = line.strip()\n",
    "    if len(line) > 0:\n",
    "      out.append(line)\n",
    "  return out\n",
    "\n",
    "train_txt = clean_lines(train_txt)\n",
    "val_txt = clean_lines(val_txt)\n",
    "\n",
    "# ابزار جمله بندی خیلی ساده\n",
    "def split_sentences(x):\n",
    "  out = []\n",
    "  s = []\n",
    "  for tok in x.split():\n",
    "    s.append(tok)\n",
    "    if tok.endswith(('.','!','?','.\"',\"!'\",\"?'\")):\n",
    "      out.append(\" \".join(s))\n",
    "      s = []\n",
    "  if s:\n",
    "    out.append(\" \".join(s))\n",
    "  return out if out else [x]\n",
    "\n",
    "# نمونه گیری طول با توزیع پواسون\n",
    "def simple_span_len(lam=3):\n",
    "  L=0\n",
    "  p = math.exp(-lam)\n",
    "  F = p\n",
    "  u = random.random()\n",
    "  while u > F:\n",
    "    L += 1\n",
    "    p *= lam/L\n",
    "    F += p\n",
    "  return max(L,1)\n",
    "\n",
    "\n",
    "def text_infilling_token_ids(ids,mask_ratio=0.3,lam=3):\n",
    "  L = len(ids)\n",
    "  num_to_mask = max(1,int(mask_ratio*L))\n",
    "  masked = ids[:]\n",
    "  covered = set()\n",
    "  while len(covered) < num_to_mask:\n",
    "    start = random.randrange(0,L)\n",
    "    if start in covered:\n",
    "      continue\n",
    "    span_len = simple_span_len(lam)\n",
    "    end = min(L,start+span_len)\n",
    "    for i in range(start,end):\n",
    "      if i not in covered:\n",
    "        masked[i] = MASK_ID\n",
    "        covered.add(i)\n",
    "  return masked\n",
    "\n",
    "def sentence_permute(text):\n",
    "  sents = split_sentences(text)\n",
    "  random.shuffle(sents)\n",
    "  return \" \".join(sents)\n",
    "\n",
    "def apply_noise(text,do_sentperm=True,mask_ratio = 0.3,lam=3):\n",
    "  if do_sentperm:\n",
    "    text = sentence_permute(text)\n",
    "\n",
    "  ids = tokenizer(text,truncation=True,max_length=MAX_INPUT,add_special_tokens=False)[\"input_ids\"]\n",
    "  if len(ids) == 0:\n",
    "    return None\n",
    "\n",
    "  noisy_ids = text_infilling_token_ids(ids,mask_ratio=mask_ratio,lam=lam)\n",
    "\n",
    "  def pack(arr,max_len):\n",
    "    arr = [BOS_ID] + arr[:max_len-2] + [EOS_ID]\n",
    "    attn = [1]*len(arr)\n",
    "    if len(arr) < max_len:\n",
    "      pad_len = max_len - len(arr)\n",
    "      arr += [PAD_ID]*pad_len\n",
    "      attn += [0]*pad_len\n",
    "    return arr, attn\n",
    "\n",
    "  noisy_imp, noisy_attn = pack(noisy_ids,MAX_INPUT)\n",
    "  clean_tgt, _  = pack(ids,MAX_TARGET)\n",
    "\n",
    "  return {\n",
    "      \"input_ids\":noisy_imp,\n",
    "      \"attention_mask\":noisy_attn,\n",
    "      \"labels\":clean_tgt\n",
    "  }\n",
    "\n",
    "\n",
    "def make_tensor_dataset(texts, n_limits=None):\n",
    "  rows = []\n",
    "  count = 0\n",
    "  for t in texts:\n",
    "    ex = apply_noise(t,do_sentperm=True,mask_ratio=0.3,lam=3)\n",
    "    if ex is not None:\n",
    "      rows.append(ex)\n",
    "      count += 1\n",
    "      if n_limits is not None and count >= n_limits:\n",
    "          break\n",
    "\n",
    "  input_ids = torch.tensor([r[\"input_ids\"] for r in rows], dtype=torch.long)\n",
    "  attention_mask = torch.tensor([r[\"attention_mask\"] for r in rows], dtype=torch.long)\n",
    "  labels = torch.tensor([r[\"labels\"] for r in rows], dtype=torch.long)\n",
    "  return {\"input_ids\":input_ids,\"attention_mask\":attention_mask, \"labels\":labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjTPDRhDScPS"
   },
   "outputs": [],
   "source": [
    "train_ids = make_tensor_dataset(train_txt[150000:310000],n_limits=150000)\n",
    "val_ids = make_tensor_dataset(val_txt[10000:19000], n_limits=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1LD8uVKT8JT"
   },
   "source": [
    "#### lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e9cf6953f3ef42e79f5650f2c3b31632",
      "9a771051931d4851a3fb3c59a31ba699",
      "453e958c6c224db888a44ffb5252f846",
      "e1d05b2c6c6d4567b2141e646094392a",
      "988e20479736471fa65789037b2351cf",
      "cfb23a5f9a274dd8b25b5f4356fb6bc9",
      "749aea137ce5400ea5e7a7b534feaa85",
      "e0220a085afa40eb8b697d638885f38d",
      "f923bfef369743d29cb573057caf54f5",
      "60f153df4f0348aaa58a2b2698544632",
      "c396db19e58e4d43abd3fe71f5eb7eed"
     ]
    },
    "id": "vscF1P2uTeWx",
    "outputId": "29b0d18c-20eb-4fee-b87e-3f49486a38df"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cf6953f3ef42e79f5650f2c3b31632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "class LitMiniBART(pl.LightningModule):\n",
    "  def __init__(self,model,vocab_size,d_model=256,n_heads=4,d_ff=1024,num_enc=3,num_dec=3):\n",
    "    super().__init__()\n",
    "    self.model = MiniBART(vocab_size,d_model,n_heads,d_ff,num_enc,num_dec)\n",
    "    self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    self.val_preds = []\n",
    "    self.val_labels = []\n",
    "\n",
    "  def forward(self,src_ids,tgt_ids):\n",
    "    return self.model(src_ids,tgt_ids)\n",
    "\n",
    "  def training_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"train_loss\",loss,prog_bar=True)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    logits = self(batch[\"input_ids\"],batch[\"labels\"])\n",
    "    shift_logits = logits[:,:-1].contiguous()\n",
    "    shift_labels = batch[\"labels\"][:,1:].contiguous()\n",
    "    loss = self.loss_fn(shift_logits.view(-1,shift_logits.size(-1)),shift_labels.view(-1))\n",
    "    self.log(\"val_loss\",loss,prog_bar=True)\n",
    "\n",
    "    generated_ids = torch.argmax(logits,dim=-1)\n",
    "    preds = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(batch[\"labels\"],skip_special_tokens=True)\n",
    "    self.val_preds.extend(preds)\n",
    "    self.val_labels.extend(labels)\n",
    "\n",
    "  def on_validation_epoch_end(self) :\n",
    "    if len(self.val_preds) > 0:\n",
    "      results = rouge.compute(predictions=self.val_preds,references=self.val_labels,use_stemmer=True)\n",
    "      self.log_dict({f\"val_{k}\":v for k,v in results.items()},prog_bar=True)\n",
    "      self.val_preds = []\n",
    "      self.val_labels = []\n",
    "\n",
    "  def configure_optimizers(self) :\n",
    "    opt = torch.optim.AdamW(self.parameters(),lr=5e-4,betas=(0.9,0.98),weight_decay=0.01)\n",
    "    sch = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.1, total_iters=500)\n",
    "    return {\"optimizer\":opt,\"lr_scheduler\":{\"scheduler\":sch,\"interval\":\"step\"}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_JMhEINVTCr"
   },
   "source": [
    "#### dataloader , train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1j1-ge0nVXz2"
   },
   "outputs": [],
   "source": [
    "def to_dataset_obj(d):\n",
    "  return TensorDataset(d[\"input_ids\"],d[\"attention_mask\"],d[\"labels\"])\n",
    "\n",
    "class WrappedSet(torch.utils.data.Dataset):\n",
    "  def __init__(self,d):\n",
    "    self.input_ids = d[\"input_ids\"]\n",
    "    self.attention_mask = d[\"attention_mask\"]\n",
    "    self.labels = d[\"labels\"]\n",
    "\n",
    "  def __len__(self): return self.input_ids.size(0)\n",
    "  def __getitem__(self,idx):\n",
    "    return {\n",
    "        \"input_ids\":self.input_ids[idx],\n",
    "        \"attention_mask\":self.attention_mask[idx],\n",
    "        \"labels\":self.labels[idx]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4aJyN2pWUOT",
    "outputId": "5171eb01-294f-4f9a-e5d8-0e883c83b643"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train_wrapped = WrappedSet(train_ids)\n",
    "val_wrapped = WrappedSet(val_ids)\n",
    "\n",
    "train_loader = DataLoader(train_wrapped,batch_size=4,shuffle=True,num_workers=2)\n",
    "val_loader = DataLoader(val_wrapped,batch_size=4,shuffle=False,num_workers=2)\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"minibart_denoise\")\n",
    "lit_model = LitMiniBART(model=model, vocab_size=tokenizer.vocab_size)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    max_epochs=2,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590,
     "referenced_widgets": [
      "c156d006d106406f9c315cbc30cd22e0",
      "35febe862c4b44a190f603bf3ce2dbd5",
      "973393bdf77e49e9955a53cb3cf050db",
      "a3887d006f97416296350efbb8992d60",
      "bb9af6a4ed1b404a94967f312f0a4edc",
      "ba4fb5ccab4844bf82511b86d92f2e9b",
      "3e47a1bdaafd49a8a0a12924547ef391",
      "4998c315fd0b4eb1a03a7ac79faa3057",
      "b14d64a297d44a08940129445a2d95e1",
      "ab0561e0857e4101b1c9651fa858fe6f",
      "44f5945a7d4742bb9c98d9f0fd27ab29",
      "1ab43439902a413da92a0456aad5c24c",
      "7be77a81d2d8497190c5425ae77b44f4",
      "7923763df3eb455182c8dd99db6cfcc4",
      "1f996390a9ab421091b8a69d715cb25d",
      "cd4925146fe04ad3970fbd3c7c89cb97",
      "55710a3f2aab4952be7e4d5820ba49bd",
      "033c9adcb5e2416d99e3d5cdd6fe54be",
      "0b8b1a3270294d38824abeaefd90017b",
      "d67730df57574588bbb5248d56c4ebe9",
      "195db3857d0b47fe836570791562fd06",
      "6ffb39716ac44a92904c7567652c066c"
     ]
    },
    "id": "GLyM61fXXHHy",
    "outputId": "225804d0-18f4-40a8-b6cd-a88fd1092751"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c156d006d106406f9c315cbc30cd22e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab43439902a413da92a0456aad5c24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn2Jzy9QGKhA"
   },
   "source": [
    "## **TRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4ymyIrXxHDQ"
   },
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305,
     "referenced_widgets": [
      "449d3927764b429d8b881d0a7127b684",
      "7f62a8c9c40c436aacfc5ca6f01e205e",
      "0369a9702fbf4ccf8ccd29106fb0d7bc",
      "87e9df6be3eb4183a3677f896cd2729b",
      "53faf9e15bd0412d88afee32acf938e7",
      "7d7dd7f77ad0436786a5a27a06649172",
      "92b9e745091f494aa5c10cf81e8e7295",
      "8eaf7226a66841968ab5f485b0ec9bf8",
      "3842e67c484f4fc0bb972d6f255b70eb",
      "8739057050104397b735a0c284859d75",
      "46efdac9ac554224b488e4c897475f4c",
      "8eadbe7ad595411e9e94c3d0d7cd4977",
      "785cf31d18d940e5bb0b9703b368e8d4",
      "c37284ab4a2049ae9941205d6364adfb",
      "814877c7c13a4e0880078b333346a35d",
      "71aa8b2471cf4af684c1c86f624163a5",
      "c2afe6d16c194ec88952744baae7dde1",
      "f9f4b27ca92745848003bb7eb21efc61",
      "3493a291d01a4f3ebfb75cacda54bbbe",
      "382faf8e4fd644509758b26d5b21b666",
      "624007f0ef834478acd1b034895a2d37",
      "dadb7a121ab944569d150e1936042dfc",
      "0c588f81e1c04bd4b662c5bcdfb81e45",
      "247a115a8de84bc9936b83fbf20862e7",
      "ca877f9a07a047b4ad4a2d0524d38aed",
      "a04cfb8987174e20bc3f4397f969b8cd",
      "06382a1e6c6247c4b2ce9b7603aa630c",
      "3389849e55e14953a06541b5029e6df4",
      "7f2bd7aef4794513ae3582a3168c41cf",
      "1897a4f6501c451e96b3b11cd19774dc",
      "4d9d6dba54474d20bf01fac31cfab437",
      "f86e50a0a4c3485cb49ca5c5bc8ef713",
      "aa7af1f1dc974194b2f2839987f3805e",
      "747e2b7d81d847e796579dbbdd9d9cb8",
      "a849add157c34d5d8005c9f26c487754",
      "f5f79a581cfd4552b4e52a9da2e653b9",
      "2e33cf425d084e799191492250054470",
      "b791e6d69a004fc1b03e7297a719d608",
      "c888786f6cea452796dc84d49053ca83",
      "781876d9083f471fb39219f9e53667cd",
      "90e54d382a0f45a3bf20056771bed69b",
      "5f4be4d231af494eb2c2bc64fb69cda6",
      "359235e904ec4b2cb58a0bcd02604dfc",
      "a338d345d79f4badbbf44f3394b8cc87",
      "9be70880c4c948e8b581e77ebd96eb97",
      "a08f83fd5b764c2daa1e3a6a0b74977c",
      "b0526c9810634e7290ef8e1b07d75fef",
      "2444e3f8fc23435097ca011819a6c898",
      "c4448834c1154efb8efa1533cd2addd7",
      "b72b8b8013bd4dd09af9e2b6d254b8ab",
      "d7f20d1c03cf442d9fb7a9b089562d0a",
      "0af69fb22d0349f987c5befcdcc194e9",
      "ac25e30bf9d44bbfbe63073f2f06423e",
      "242aaa1b95014624ab10d9c861e6e16a",
      "193e7f76ec4f491dafc89e53a6baf85a",
      "099b210d37dc43439bcee355345aa139",
      "6c5d5a0f03ae4e66b33f7ed5d40f796f",
      "fdad29ec5f674676923ebec6011d7983",
      "1ab57101730f48ca9934ab893eaa1ae7",
      "156c47ed927d49eab6e7e59fc7fbff5c",
      "a72d25835eb84928a8a7aea83357c5f9",
      "ec69bd1176d54528aa9600c460e57ba0",
      "66c860a051c343eba1ae93cab3db36cd",
      "4bde9aef4ece44f3a2ca8c8f23f3872e",
      "0f36e7c0615842e7a3775253e6fc4809",
      "b08d0739ef8844c5925aeb85b00ff99b",
      "71989dc4eabf417fb869277f871987c7",
      "29672c25eda645baa599176af30572de",
      "530516f336494dbaaca3999a0eb2e537",
      "b9b922aec9fc47d08bf3fcfe2ab5fb41",
      "741463a80e3d40c2a14e6465724add57",
      "3c49d83b53ca416dab5b2c7154ab798d",
      "1e0100ceac04424da2505fefac2d93a5",
      "9af7f050dc9940cb838d85cb250cf011",
      "d0caf332a8144a0ebd8fb2aecab040d0",
      "eb451998339743aca991e38d07cf5c05",
      "14352737010b47198f24218591991a29",
      "7ab74612f2cf46d3a72f6e98a9aed1e6",
      "194aeca61734428fa83b4b5f4e8bb699",
      "59c2dd134db94eefbffdf4772cf351a2",
      "01c1f9495bb3422e90bebd049ab357b9",
      "a827f09730d84559935ae60b336ff05a",
      "9c0ef6ae176547fcb8b06b1770670a72",
      "e3edfc561ac14b59ad3aaf78469ab7e0",
      "88a4b5857de54a32947c5d07cc5db56e",
      "50e6616f814147ecbc0a20ee6d3d377d",
      "6b5b9c42d2404f8bbb56625941cebc87",
      "6bd01682d11c474c899911455e552b5c",
      "7286ec06dfdb4130b01d833e2f89493b",
      "03918b950ee443d293e0d5703d4244f8",
      "d2dc0f183ced426bb8c686db981107e4",
      "4eee16a2998944ddb0ac57c61758166e",
      "958c8838043049f499c7addf40ac858d",
      "66bd154054bd4d2787a46d12da892061",
      "f2966df12280437aa3fc2b3b4b27a6ae",
      "a7afca4362b940499a0f5cd985da8d2a",
      "5129c801e9854a02836dbc8613443b64",
      "92cdd0a43d6246908085a13ed1300b98",
      "234175c7ba8b41cfa858c31a0c7cb894"
     ]
    },
    "collapsed": true,
    "id": "kMj06JHIxLzr",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "da797f20-536e-4596-a90e-7d52ff344bec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449d3927764b429d8b881d0a7127b684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eadbe7ad595411e9e94c3d0d7cd4977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c588f81e1c04bd4b662c5bcdfb81e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747e2b7d81d847e796579dbbdd9d9cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be70880c4c948e8b581e77ebd96eb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099b210d37dc43439bcee355345aa139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71989dc4eabf417fb869277f871987c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab74612f2cf46d3a72f6e98a9aed1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7286ec06dfdb4130b01d833e2f89493b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_dmail = load_dataset(\"cnn_dailymail\",\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4dQ6alZxaY-"
   },
   "outputs": [],
   "source": [
    "MAX_INPUT = 512\n",
    "MAX_TARGET = 128\n",
    "\n",
    "def prepprocess(batch):\n",
    "  inputs = tokenizer(\n",
    "      batch[\"article\"],max_length=MAX_INPUT,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  targets = tokenizer(\n",
    "      batch[\"highlights\"],max_length=MAX_TARGET,padding=\"max_length\",truncation=True\n",
    "  )\n",
    "  inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "771ec4a971b74dcf9a92720c0d09927a",
      "95f5e5d8842d41558d018165315a3c06",
      "06fbf5f54a46450b8d31913c7637e60e",
      "b95906fc280a43ca8d7996e308ba4649",
      "69bdaf98656546879ca13b4f88a539ce",
      "31db853d4f244b49b40af064656391db",
      "0dd1f6ae1e90474395240d26273149ad",
      "83cc6d1aace64254930d95ca4bd99a6d",
      "3bed3e8e66be49bc9ec28ba50d69b4b4",
      "caac1b3428ad423084d475353ff021f2",
      "583317b6b5f94671ab549ed2c7b358ec",
      "0e861c79d68440e0b34ccdfb100eb0ce",
      "10454cc10b5a41cab7e406f13c47045c",
      "8328387c8b044555b3cf7228175b8313",
      "78b24a133afe4b928d5b65e521752bf9",
      "40250ebfbe924fdf9315d367b767d135",
      "45053b16001e4c1d94530a86d77465ce",
      "e0ae32a77ffb4a90ab53aff6490ce52a",
      "016c56274c874e5884150477f2b0427d",
      "35fde2dfee634af493086e85f41d32ab",
      "dbf6e1625e604a11b482b76cdc6d2c48",
      "b84e6253f0614c8e95dd7a5df907177e"
     ]
    },
    "id": "lCWjtT-zyM9d",
    "outputId": "949e0db7-d9a1-427b-eed4-431227e7873f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771ec4a971b74dcf9a92720c0d09927a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e861c79d68440e0b34ccdfb100eb0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cnn_dmail = cnn_dmail[\"train\"].select(range(80000,160000))\n",
    "val_cnn_dmail = cnn_dmail[\"validation\"].select(range(6000,11000))\n",
    "\n",
    "tokenized_train_cnn_dmail = train_cnn_dmail.map(prepprocess,batched=True,remove_columns=train_cnn_dmail.column_names)\n",
    "tokenized_val_cnn_dmail = val_cnn_dmail.map(prepprocess,batched=True,remove_columns=val_cnn_dmail.column_names)\n",
    "\n",
    "train_cnn_dmail = tokenized_train_cnn_dmail.with_format(\"torch\")\n",
    "val_cnn_dmail = tokenized_val_cnn_dmail.with_format(\"torch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m70jcKPY4end"
   },
   "source": [
    "### **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tO04tRwDNwE",
    "outputId": "c0952e68-f24d-42b0-f646-3c76a96e16d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader_cnn_dmail = DataLoader(train_cnn_dmail,batch_size=4,shuffle=True)\n",
    "val_loader_cnn_dmail = DataLoader(val_cnn_dmail,batch_size=4,shuffle=False)\n",
    "\n",
    "trainer_cnndmail = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    max_epochs=2,\n",
    "    gradient_clip_val=1.0,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "44a8020901634e3fa31e2c7886135c19",
      "315ab2d2c9d647ceb7ff55d92ccda9f5",
      "227edc7a147b40cca8cd609b691a4fc1",
      "948e55565743480497e3596fbbaa50a3",
      "b3e7faba299649a4967771291dd31faf",
      "33c8076398484663b99bc35d839724bb",
      "8dc502e23f4a4339a21f28abb0878095",
      "3445ac2513264eb49061b18b7d6a371a",
      "bdfe50f1b5fa4a4ab7269ae82e077743",
      "4016c9dca4694f75951656c673f099e1",
      "600fb50921e5491296362d4751cbbcd1",
      "0f793ee9895246ffa5f541a86853eea5",
      "70468650b9904bd9aa0f9efafff66db1",
      "d99929cabc0d45c8be8a400a83dd6ff2",
      "a58141527c29438ca02f6610d59a4bcf",
      "884f9a71f280407bb5c2cec04387be3f",
      "25400dff37024d5c856de452452666d2",
      "91d45dacdd9841a8a8986448d37482a9",
      "a63a3adb3c3641e0a128a3281087a1fc",
      "b5263fc8da70444a9e5cd75044964465",
      "fcf40f4e768b463eb120c2562f6f24d9",
      "ee2516a329f647abb0f415d11728520f",
      "778c13d62e9044c391001c2edc865f70",
      "d97d25dc3628410f8d7cde72f761883e",
      "d0d4bd49476f4d1da276c43580c8820c",
      "e3a2a56437814bf59bba39ed1b99d213",
      "3a2f4ff934f2488a9ffe3d50055c9d10",
      "c2da7aded8724300a7dcd5ea25a2cb0f",
      "d95b449f9f514de1b57bd0d4cb4f83b6",
      "ec2eacfa306d4c9ab28ac58f7a329890",
      "3e269a880a944ba2a6de4b1172004a3c",
      "78713ea0471e480d8ec7003f41e2767e",
      "4c9b7830e6054a799e40f5f571b7c564",
      "5b9f1141ed9446e2bf811790d8448ad6",
      "0ff3172f1952479b99f975ab4da0c4be",
      "c4cbd6a25a53485b9a8956d5304f1635",
      "0a9ec5774ccd41f4be41fe1d2c80b25c",
      "a0a3ba3c21104257a42f928a8d40cb6d",
      "17894e1261334c8190ecf55da4b8a891",
      "2c6e39883d7d48f38a00df52eab60832",
      "7fce45ba1197441bae96af5b5231a97f",
      "0c8c028536e94cc9a3d4dc486fc93b02",
      "22bbdca84bc54de0b6f1d5cd3db9e044",
      "7f37b537869b4ef487dcfd99efe255b8"
     ]
    },
    "id": "Gh-EjLIo53q6",
    "outputId": "f9cfab42-676f-4f42-8596-8dcf2406b023"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MiniBART         | 31.4 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.585   Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a8020901634e3fa31e2c7886135c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f793ee9895246ffa5f541a86853eea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778c13d62e9044c391001c2edc865f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9f1141ed9446e2bf811790d8448ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer_cnndmail.fit(lit_model,train_loader_cnn_dmail,val_loader_cnn_dmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjxsieTXvdT7",
    "outputId": "a515df03-2768-4849-9692-2be3d2516394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/vocab.json',\n",
       " '/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/merges.txt',\n",
       " '/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/added_tokens.json',\n",
       " '/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Labratory_13_miniBAR_pretrain.pth\"\n",
    "torch.save(lit_model.model.state_dict(),save_path)\n",
    "tokenizer_path = \"/content/drive/MyDrive/Labratory_13_miniBAR_pretrain_tokenizer.json\"\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  }
 ],
 "metadata": {
  "cells": [],
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python",
    "version": "3.10.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
